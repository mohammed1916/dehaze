{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef58ae73",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:20.861914Z",
     "iopub.status.busy": "2025-04-12T13:09:20.861625Z",
     "iopub.status.idle": "2025-04-12T13:09:32.124318Z",
     "shell.execute_reply": "2025-04-12T13:09:32.123654Z"
    },
    "papermill": {
     "duration": 11.276571,
     "end_time": "2025-04-12T13:09:32.125878",
     "exception": false,
     "start_time": "2025-04-12T13:09:20.849307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.nn.init import _calculate_fan_in_and_fan_out\n",
    "from timm.layers import to_2tuple, trunc_normal_\n",
    "import os\n",
    "import torchvision.utils as utils\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import glob\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose, ToPILImage\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from random import randrange\n",
    "import time\n",
    "from math import log10\n",
    "from skimage import measure\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from torch.nn.init import trunc_normal_\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087ddce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.148402Z",
     "iopub.status.busy": "2025-04-12T13:09:32.148046Z",
     "iopub.status.idle": "2025-04-12T13:09:32.151313Z",
     "shell.execute_reply": "2025-04-12T13:09:32.150674Z"
    },
    "papermill": {
     "duration": 0.015315,
     "end_time": "2025-04-12T13:09:32.152405",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.137090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2c1d5",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 0.009983,
     "end_time": "2025-04-12T13:09:32.172516",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.162533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RevisedLayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc15eaf",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.193443Z",
     "iopub.status.busy": "2025-04-12T13:09:32.193242Z",
     "iopub.status.idle": "2025-04-12T13:09:32.199574Z",
     "shell.execute_reply": "2025-04-12T13:09:32.198976Z"
    },
    "papermill": {
     "duration": 0.01803,
     "end_time": "2025-04-12T13:09:32.200726",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.182696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RevisedLayerNorm(nn.Module):\n",
    "    \"\"\"Revised LayerNorm\"\"\"\n",
    "    def __init__(self, embed_dim, epsilon=1e-5, detach_gradient=False):\n",
    "        super(RevisedLayerNorm, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.detach_gradient = detach_gradient\n",
    "\n",
    "        self.scale = nn.Parameter(torch.ones((1, embed_dim, 1, 1)))\n",
    "        self.shift = nn.Parameter(torch.zeros((1, embed_dim, 1, 1)))\n",
    "\n",
    "        self.scale_mlp = nn.Conv2d(1, embed_dim, 1)\n",
    "        self.shift_mlp = nn.Conv2d(1, embed_dim, 1)\n",
    "\n",
    "        trunc_normal_(self.scale_mlp.weight, std=.02)\n",
    "        nn.init.constant_(self.scale_mlp.bias, 1)\n",
    "\n",
    "        trunc_normal_(self.shift_mlp.weight, std=.02)\n",
    "        nn.init.constant_(self.shift_mlp.bias, 0)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        mean_value = torch.mean(input_tensor, dim=(1, 2, 3), keepdim=True)\n",
    "        std_value = torch.sqrt((input_tensor - mean_value).pow(2).mean(dim=(1, 2, 3), keepdim=True) + self.epsilon)\n",
    "\n",
    "        normalized_tensor = (input_tensor - mean_value) / std_value\n",
    "\n",
    "        if self.detach_gradient:\n",
    "            rescale, rebias = self.scale_mlp(std_value.detach()), self.shift_mlp(mean_value.detach())\n",
    "        else:\n",
    "            rescale, rebias = self.scale_mlp(std_value), self.shift_mlp(mean_value)\n",
    "\n",
    "        output = normalized_tensor * self.scale + self.shift\n",
    "        return output, rescale, rebias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9047af4",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.222052Z",
     "iopub.status.busy": "2025-04-12T13:09:32.221814Z",
     "iopub.status.idle": "2025-04-12T13:09:32.229255Z",
     "shell.execute_reply": "2025-04-12T13:09:32.228635Z"
    },
    "papermill": {
     "duration": 0.019569,
     "end_time": "2025-04-12T13:09:32.230395",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.210826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, depth, input_channels, hidden_channels=None, output_channels=None):\n",
    "        super().__init__()\n",
    "        output_channels = output_channels or input_channels\n",
    "        hidden_channels = hidden_channels or input_channels\n",
    "\n",
    "        self.depth = depth\n",
    "\n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, hidden_channels, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_channels, output_channels, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.apply(self._initialize_weights)\n",
    "\n",
    "    def _initialize_weights(self, layer):\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            gain = (8 * self.depth) ** (-1 / 4)\n",
    "            fan_in, fan_out = torch.nn.init._calculate_fan_in_and_fan_out(layer.weight)\n",
    "            std = gain * math.sqrt(2.0 / float(fan_in + fan_out))\n",
    "            trunc_normal_(layer.weight, std=std)\n",
    "            if layer.bias is not None:\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp_layers(x)\n",
    "\n",
    "\n",
    "def partition_into_windows(tensor, window_size):\n",
    "    \"\"\"Splits the input tensor into non-overlapping windows.\"\"\"\n",
    "    batch_size, height, width, channels = tensor.shape\n",
    "    assert height % window_size == 0 and width % window_size == 0, \"Height and width must be divisible by window_size\"\n",
    "\n",
    "    tensor = tensor.view(\n",
    "        batch_size, height // window_size, window_size, width // window_size, window_size, channels\n",
    "    )\n",
    "    windows = tensor.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size**2, channels)\n",
    "    return windows\n",
    "\n",
    "\n",
    "def merge_windows(windows, window_size, height, width):\n",
    "    \"\"\"Reconstructs the original tensor from partitioned windows.\"\"\"\n",
    "    batch_size = windows.shape[0] // ((height * width) // (window_size**2))\n",
    "    tensor = windows.view(\n",
    "        batch_size, height // window_size, width // window_size, window_size, window_size, -1\n",
    "    )\n",
    "    tensor = tensor.permute(0, 1, 3, 2, 4, 5).contiguous().view(batch_size, height, width, -1)\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd67ee",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 0.010551,
     "end_time": "2025-04-12T13:09:32.251201",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.240650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "441543fe",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.272335Z",
     "iopub.status.busy": "2025-04-12T13:09:32.272110Z",
     "iopub.status.idle": "2025-04-12T13:09:32.401748Z",
     "shell.execute_reply": "2025-04-12T13:09:32.400999Z"
    },
    "papermill": {
     "duration": 0.141806,
     "end_time": "2025-04-12T13:09:32.403159",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.261353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 64, 16, 16]),\n",
       " torch.Size([32, 16, 64]),\n",
       " torch.Size([2, 16, 16, 64]),\n",
       " True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize the MultiLayerPerceptron with sample parameters\n",
    "depth = 4\n",
    "input_channels = 64\n",
    "hidden_channels = 128\n",
    "output_channels = 64\n",
    "\n",
    "mlp = MultiLayerPerceptron(depth, input_channels, hidden_channels, output_channels)\n",
    "\n",
    "# Create a random tensor to test MLP (batch_size=2, channels=64, height=16, width=16)\n",
    "input_tensor = torch.randn(2, 64, 16, 16)\n",
    "output_tensor = mlp(input_tensor)\n",
    "\n",
    "# Check output shape\n",
    "mlp_output_shape = output_tensor.shape\n",
    "\n",
    "# Test window partition and merging\n",
    "batch_size, height, width, channels = 2, 16, 16, 64\n",
    "window_size = 4\n",
    "\n",
    "# Create a random tensor for window functions (B, H, W, C) format\n",
    "input_window_tensor = torch.randn(batch_size, height, width, channels)\n",
    "\n",
    "# Apply partitioning and merging\n",
    "windows = partition_into_windows(input_window_tensor, window_size)\n",
    "reconstructed_tensor = merge_windows(windows, window_size, height, width)\n",
    "\n",
    "# Check shapes\n",
    "windows_shape = windows.shape\n",
    "reconstructed_shape = reconstructed_tensor.shape\n",
    "\n",
    "# Validate if the reconstruction matches the original input shape\n",
    "is_shape_correct = reconstructed_shape == input_window_tensor.shape\n",
    "\n",
    "# Output results\n",
    "mlp_output_shape, windows_shape, reconstructed_shape, is_shape_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "779c3bb7",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.425118Z",
     "iopub.status.busy": "2025-04-12T13:09:32.424855Z",
     "iopub.status.idle": "2025-04-12T13:09:32.431619Z",
     "shell.execute_reply": "2025-04-12T13:09:32.430948Z"
    },
    "papermill": {
     "duration": 0.019079,
     "end_time": "2025-04-12T13:09:32.432815",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.413736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LocalWindowAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, window_size, num_heads):\n",
    "        \"\"\"Self-attention mechanism within local windows.\"\"\"\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.window_size = window_size  # (height, width)\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        self.scaling_factor = head_dim ** -0.5  # Scaled dot-product attention\n",
    "\n",
    "        # Compute and store relative positional encodings\n",
    "        relative_positional_encodings = compute_log_relative_positions(self.window_size)\n",
    "        self.register_buffer(\"relative_positional_encodings\", relative_positional_encodings)\n",
    "\n",
    "        # Learnable transformation of relative position embeddings\n",
    "        self.relative_mlp = nn.Sequential(\n",
    "            nn.Linear(2, 256, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_heads, bias=True)\n",
    "        )\n",
    "\n",
    "        self.attention_softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, qkv):\n",
    "        \"\"\"Computes attention scores and applies self-attention within a window.\"\"\"\n",
    "        batch_size, num_tokens, _ = qkv.shape\n",
    "\n",
    "        # Reshape qkv into separate query, key, and value tensors\n",
    "        qkv = qkv.reshape(batch_size, num_tokens, 3, self.num_heads, self.embed_dim // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # Unpacking query, key, and value\n",
    "\n",
    "        # Scale query for stable attention computation\n",
    "        q = q * self.scaling_factor\n",
    "        attention_scores = q @ k.transpose(-2, -1)\n",
    "\n",
    "        # Compute relative position bias\n",
    "        relative_bias = self.relative_mlp(self.relative_positional_encodings)\n",
    "        relative_bias = relative_bias.permute(2, 0, 1).contiguous()  # Shape: (num_heads, window_size², window_size²)\n",
    "        attention_scores = attention_scores + relative_bias.unsqueeze(0)\n",
    "\n",
    "        # Apply softmax and compute weighted values\n",
    "        attention_weights = self.attention_softmax(attention_scores)\n",
    "        output = (attention_weights @ v).transpose(1, 2).reshape(batch_size, num_tokens, self.embed_dim)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c4dcc1",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.454123Z",
     "iopub.status.busy": "2025-04-12T13:09:32.453902Z",
     "iopub.status.idle": "2025-04-12T13:09:32.457662Z",
     "shell.execute_reply": "2025-04-12T13:09:32.457095Z"
    },
    "papermill": {
     "duration": 0.015719,
     "end_time": "2025-04-12T13:09:32.458806",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.443087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_log_relative_positions(window_size):\n",
    "    \"\"\"Computes log-scaled relative position embeddings for a given window size.\"\"\"\n",
    "    coord_range = torch.arange(window_size)\n",
    "\n",
    "    # Create coordinate grid\n",
    "    coord_grid = torch.stack(torch.meshgrid([coord_range, coord_range]))  # Shape: (2, window_size, window_size)\n",
    "    \n",
    "    # Flatten coordinates\n",
    "    flattened_coords = torch.flatten(coord_grid, 1)  # Shape: (2, window_size * window_size)\n",
    "\n",
    "    # Compute relative positions\n",
    "    relative_positions = flattened_coords[:, :, None] - flattened_coords[:, None, :]  # Shape: (2, window_size^2, window_size^2)\n",
    "\n",
    "    # Format and apply log transformation\n",
    "    relative_positions = relative_positions.permute(1, 2, 0).contiguous()  # Shape: (window_size^2, window_size^2, 2)\n",
    "    log_relative_positions = torch.sign(relative_positions) * torch.log(1. + relative_positions.abs())\n",
    "\n",
    "    return log_relative_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5c96e9",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.480169Z",
     "iopub.status.busy": "2025-04-12T13:09:32.479945Z",
     "iopub.status.idle": "2025-04-12T13:09:32.493465Z",
     "shell.execute_reply": "2025-04-12T13:09:32.492659Z"
    },
    "papermill": {
     "duration": 0.025485,
     "end_time": "2025-04-12T13:09:32.494578",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.469093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdaptiveAttention(nn.Module):\n",
    "    def __init__(self, network_depth, embed_dim, num_heads, window_size, shift_size, enable_attention=False, conv_mode=None):\n",
    "        \"\"\"Hybrid attention-convolution module with optional window-based attention.\"\"\"\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "\n",
    "        self.network_depth = network_depth\n",
    "        self.enable_attention = enable_attention\n",
    "        self.conv_mode = conv_mode\n",
    "\n",
    "        # Define convolutional processing based on mode\n",
    "        if self.conv_mode == 'Conv':\n",
    "            self.conv_layer = nn.Sequential(\n",
    "                nn.Conv2d(embed_dim, embed_dim, kernel_size=3, padding=1, padding_mode='reflect'),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(embed_dim, embed_dim, kernel_size=3, padding=1, padding_mode='reflect')\n",
    "            )\n",
    "\n",
    "        if self.conv_mode == 'DWConv':\n",
    "            self.conv_layer = nn.Conv2d(embed_dim, embed_dim, kernel_size=5, padding=2, groups=embed_dim, padding_mode='reflect')\n",
    "\n",
    "        if self.conv_mode == 'DWConv' or self.enable_attention:\n",
    "            self.value_projection = nn.Conv2d(embed_dim, embed_dim, 1)\n",
    "            self.output_projection = nn.Conv2d(embed_dim, embed_dim, 1)\n",
    "\n",
    "        if self.enable_attention:\n",
    "            self.query_key_projection = nn.Conv2d(embed_dim, embed_dim * 2, 1)\n",
    "            self.window_attention = LocalWindowAttention(embed_dim, window_size, num_heads)\n",
    "\n",
    "        self.apply(self._initialize_weights)\n",
    "\n",
    "    def _initialize_weights(self, module):\n",
    "        \"\"\"Custom weight initialization.\"\"\"\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            weight_shape = module.weight.shape\n",
    "\n",
    "            if weight_shape[0] == self.embed_dim * 2:  # Query-Key projection\n",
    "                fan_in, fan_out = _calculate_fan_in_and_fan_out(module.weight)\n",
    "                std = math.sqrt(2.0 / float(fan_in + fan_out))\n",
    "                trunc_normal_(module.weight, std=std)\n",
    "            else:\n",
    "                gain = (8 * self.network_depth) ** (-1/4)\n",
    "                fan_in, fan_out = _calculate_fan_in_and_fan_out(module.weight)\n",
    "                std = gain * math.sqrt(2.0 / float(fan_in + fan_out))\n",
    "                trunc_normal_(module.weight, std=std)\n",
    "\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def pad_for_window_processing(self, x, shift=False):\n",
    "        \"\"\"Pads the input tensor to fit window processing requirements.\"\"\"\n",
    "        _, _, height, width = x.size()\n",
    "        pad_h = (self.window_size - height % self.window_size) % self.window_size\n",
    "        pad_w = (self.window_size - width % self.window_size) % self.window_size\n",
    "\n",
    "        if shift:\n",
    "            x = F.pad(x, (self.shift_size, (self.window_size - self.shift_size + pad_w) % self.window_size,\n",
    "                          self.shift_size, (self.window_size - self.shift_size + pad_h) % self.window_size), mode='reflect')\n",
    "        else:\n",
    "            x = F.pad(x, (0, pad_w, 0, pad_h), 'reflect')\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Computes the output with optional attention and convolution.\"\"\"\n",
    "        batch_size, channels, height, width = x.shape\n",
    "\n",
    "        if self.conv_mode == 'DWConv' or self.enable_attention:\n",
    "            v_proj = self.value_projection(x)\n",
    "\n",
    "        if self.enable_attention:\n",
    "            qk_proj = self.query_key_projection(x)\n",
    "            qkv = torch.cat([qk_proj, v_proj], dim=1)\n",
    "\n",
    "            # Apply padding for shifted window processing\n",
    "            padded_qkv = self.pad_for_window_processing(qkv, self.shift_size > 0)\n",
    "            padded_height, padded_width = padded_qkv.shape[2:]\n",
    "\n",
    "            # Partition into windows\n",
    "            padded_qkv = padded_qkv.permute(0, 2, 3, 1)\n",
    "            qkv_windows = partition_into_windows(padded_qkv, self.window_size)  # (num_windows * batch, window_size², channels)\n",
    "\n",
    "            # Apply window-based attention\n",
    "            attn_windows = self.window_attention(qkv_windows)\n",
    "\n",
    "            # Merge back to original spatial dimensions\n",
    "            merged_output = merge_windows(attn_windows, self.window_size, padded_height, padded_width)\n",
    "\n",
    "            # Reverse the cyclic shift\n",
    "            attn_output = merged_output[:, self.shift_size:(self.shift_size + height), self.shift_size:(self.shift_size + width), :]\n",
    "            attn_output = attn_output.permute(0, 3, 1, 2)\n",
    "\n",
    "            if self.conv_mode in ['Conv', 'DWConv']:\n",
    "                conv_output = self.conv_layer(v_proj)\n",
    "                output = self.output_projection(conv_output + attn_output)\n",
    "            else:\n",
    "                output = self.output_projection(attn_output)\n",
    "\n",
    "        else:\n",
    "            if self.conv_mode == 'Conv':\n",
    "                output = self.conv_layer(x)  # No attention, using convolution only\n",
    "            elif self.conv_mode == 'DWConv':\n",
    "                output = self.output_projection(self.conv_layer(v_proj))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78037b40",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.515547Z",
     "iopub.status.busy": "2025-04-12T13:09:32.515319Z",
     "iopub.status.idle": "2025-04-12T13:09:32.524180Z",
     "shell.execute_reply": "2025-04-12T13:09:32.523402Z"
    },
    "papermill": {
     "duration": 0.020653,
     "end_time": "2025-04-12T13:09:32.525353",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.504700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VisionTransformerBlock(nn.Module):\n",
    "    def __init__(self, network_depth, embed_dim, num_heads, mlp_ratio=4.0,\n",
    "                 norm_layer=nn.LayerNorm, enable_mlp_norm=False,\n",
    "                 window_size=8, shift_size=0, enable_attention=True, conv_mode=None):\n",
    "        \"\"\"\n",
    "        A transformer block that includes attention (optional) and MLP layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.enable_attention = enable_attention\n",
    "        self.enable_mlp_norm = enable_mlp_norm\n",
    "\n",
    "        self.pre_norm = norm_layer(embed_dim) if enable_attention else nn.Identity()\n",
    "        self.attention_layer = AdaptiveAttention(\n",
    "            network_depth, embed_dim, num_heads=num_heads, window_size=window_size,\n",
    "            shift_size=shift_size, enable_attention=enable_attention, conv_mode=conv_mode\n",
    "        )\n",
    "\n",
    "        self.post_norm = norm_layer(embed_dim) if enable_attention and enable_mlp_norm else nn.Identity()\n",
    "        self.mlp_layer = MultiLayerPerceptron(network_depth, embed_dim, hidden_channels=int(embed_dim * mlp_ratio))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the transformer block.\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        if self.enable_attention:\n",
    "            x, rescale, rebias = self.pre_norm(x)\n",
    "        x = self.attention_layer(x)\n",
    "        if self.enable_attention:\n",
    "            x = x * rescale + rebias\n",
    "        x = residual + x  # Residual connection\n",
    "\n",
    "        residual = x\n",
    "        if self.enable_attention and self.enable_mlp_norm:\n",
    "            x, rescale, rebias = self.post_norm(x)\n",
    "        x = self.mlp_layer(x)\n",
    "        if self.enable_attention and self.enable_mlp_norm:\n",
    "            x = x * rescale + rebias\n",
    "        x = residual + x  # Residual connection\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerStage(nn.Module):\n",
    "    def __init__(self, network_depth, embed_dim, num_layers, num_heads, mlp_ratio=4.0,\n",
    "                 norm_layer=nn.LayerNorm, window_size=8,\n",
    "                 attention_ratio=0.0, attention_placement='last', conv_mode=None):\n",
    "        \"\"\"\n",
    "        A stage of transformer blocks with configurable attention placement.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        attention_layers = int(attention_ratio * num_layers)\n",
    "\n",
    "        if attention_placement == 'last':\n",
    "            enable_attentions = [i >= num_layers - attention_layers for i in range(num_layers)]\n",
    "        elif attention_placement == 'first':\n",
    "            enable_attentions = [i < attention_layers for i in range(num_layers)]\n",
    "        elif attention_placement == 'middle':\n",
    "            enable_attentions = [\n",
    "                (i >= (num_layers - attention_layers) // 2) and (i < (num_layers + attention_layers) // 2)\n",
    "                for i in range(num_layers)\n",
    "            ]\n",
    "\n",
    "        # Build transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            VisionTransformerBlock(\n",
    "                network_depth=network_depth,\n",
    "                embed_dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                norm_layer=norm_layer,\n",
    "                window_size=window_size,\n",
    "                shift_size=0 if (i % 2 == 0) else window_size // 2,\n",
    "                enable_attention=enable_attentions[i],\n",
    "                conv_mode=conv_mode\n",
    "            ) for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the transformer stage.\n",
    "        \"\"\"\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee77df8",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.547461Z",
     "iopub.status.busy": "2025-04-12T13:09:32.547261Z",
     "iopub.status.idle": "2025-04-12T13:09:32.552769Z",
     "shell.execute_reply": "2025-04-12T13:09:32.552162Z"
    },
    "papermill": {
     "duration": 0.017283,
     "end_time": "2025-04-12T13:09:32.553948",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.536665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, patch_size=4, input_channels=3, embedding_dim=96, kernel_size=None):\n",
    "        \"\"\"\n",
    "        Patch embedding module that projects input images into token embeddings.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        if kernel_size is None:\n",
    "            kernel_size = patch_size\n",
    "\n",
    "        self.projection = nn.Conv2d(\n",
    "            input_channels, embedding_dim, kernel_size=kernel_size, stride=patch_size,\n",
    "            padding=(kernel_size - patch_size + 1) // 2, padding_mode='reflect'\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass to generate patch embeddings.\n",
    "        \"\"\"\n",
    "        return self.projection(x)\n",
    "\n",
    "\n",
    "class PatchReconstruction(nn.Module):\n",
    "    def __init__(self, patch_size=4, output_channels=3, embedding_dim=96, kernel_size=None):\n",
    "        \"\"\"\n",
    "        Patch reconstruction module that converts token embeddings back to image patches.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_channels = output_channels\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        if kernel_size is None:\n",
    "            kernel_size = 1\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                embedding_dim, output_channels * patch_size ** 2, kernel_size=kernel_size,\n",
    "                padding=kernel_size // 2, padding_mode='reflect'\n",
    "            ),\n",
    "            nn.PixelShuffle(patch_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass to reconstruct image from embeddings.\n",
    "        \"\"\"\n",
    "        return self.projection(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b271888",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.574865Z",
     "iopub.status.busy": "2025-04-12T13:09:32.574637Z",
     "iopub.status.idle": "2025-04-12T13:09:32.580385Z",
     "shell.execute_reply": "2025-04-12T13:09:32.579622Z"
    },
    "papermill": {
     "duration": 0.017407,
     "end_time": "2025-04-12T13:09:32.581526",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.564119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelectiveKernelFusion(nn.Module):\n",
    "    def __init__(self, channels, num_branches=2, reduction_ratio=8):\n",
    "        \"\"\"\n",
    "        Selective Kernel Fusion (SKFusion) module for adaptive feature selection.\n",
    "\n",
    "        Args:\n",
    "            channels (int): Number of input channels.\n",
    "            num_branches (int): Number of feature branches to fuse.\n",
    "            reduction_ratio (int): Reduction ratio for the attention mechanism.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_branches = num_branches\n",
    "        reduced_channels = max(int(channels / reduction_ratio), 4)\n",
    "        \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Conv2d(channels, reduced_channels, kernel_size=1, bias=False), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(reduced_channels, channels * num_branches, kernel_size=1, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, feature_maps):\n",
    "        \"\"\"\n",
    "        Forward pass for selective kernel fusion.\n",
    "\n",
    "        Args:\n",
    "            feature_maps (list of tensors): A list of feature maps to be fused.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The adaptively fused feature map.\n",
    "        \"\"\"\n",
    "        batch_size, channels, height, width = feature_maps[0].shape\n",
    "        \n",
    "        # Concatenate feature maps along a new dimension (num_branches)\n",
    "        stacked_features = torch.cat(feature_maps, dim=1).view(batch_size, self.num_branches, channels, height, width)\n",
    "        \n",
    "        # Compute attention weights\n",
    "        aggregated_features = torch.sum(stacked_features, dim=1)\n",
    "        attention_weights = self.channel_attention(self.global_avg_pool(aggregated_features))\n",
    "        attention_weights = self.softmax(attention_weights.view(batch_size, self.num_branches, channels, 1, 1))\n",
    "\n",
    "        # Weighted sum of input feature maps\n",
    "        fused_output = torch.sum(stacked_features * attention_weights, dim=1)\n",
    "        return fused_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db35de06",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.602539Z",
     "iopub.status.busy": "2025-04-12T13:09:32.602300Z",
     "iopub.status.idle": "2025-04-12T13:09:32.615757Z",
     "shell.execute_reply": "2025-04-12T13:09:32.614979Z"
    },
    "papermill": {
     "duration": 0.025553,
     "end_time": "2025-04-12T13:09:32.617120",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.591567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DehazingTransformer(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=4, window_size=8,\n",
    "                 embed_dims=[24, 48, 96, 48, 24],\n",
    "                 mlp_ratios=[2., 4., 4., 2., 2.],\n",
    "                 layer_depths=[16, 16, 16, 8, 8],\n",
    "                 num_heads=[2, 4, 6, 1, 1],\n",
    "                 attention_ratios=[1/4, 1/2, 3/4, 0, 0],\n",
    "                 conv_types=['DWConv', 'DWConv', 'DWConv', 'DWConv', 'DWConv'],\n",
    "                 norm_layers=[RevisedLayerNorm, RevisedLayerNorm, RevisedLayerNorm, RevisedLayerNorm, RevisedLayerNorm]):\n",
    "        super().__init__()\n",
    "\n",
    "        # Patch embedding settings\n",
    "        self.patch_size = 4\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # Initial patch embedding\n",
    "        self.patch_embed = PatchEmbedding(\n",
    "            patch_size=1, input_channels=input_channels, embedding_dim=embed_dims[0], kernel_size=3)\n",
    "\n",
    "        # Backbone layers\n",
    "        self.encoder_stage1 = TransformerStage(\n",
    "            network_depth=sum(layer_depths),\n",
    "            embed_dim=embed_dims[0],\n",
    "            num_layers=layer_depths[0],\n",
    "            num_heads=num_heads[0],\n",
    "            mlp_ratio=mlp_ratios[0],\n",
    "            norm_layer=norm_layers[0],\n",
    "            window_size=window_size,\n",
    "            attention_ratio=attention_ratios[0],\n",
    "            attention_placement='last',\n",
    "            conv_mode=conv_types[0]\n",
    "        )\n",
    "        \n",
    "        self.downsample1 = PatchEmbedding(\n",
    "            patch_size=2, input_channels=embed_dims[0], embedding_dim=embed_dims[1]\n",
    "        )\n",
    "        \n",
    "        self.skip_connection1 = nn.Conv2d(embed_dims[0], embed_dims[0], 1)\n",
    "        \n",
    "        self.encoder_stage2 = TransformerStage(\n",
    "            network_depth=sum(layer_depths),\n",
    "            embed_dim=embed_dims[1],\n",
    "            num_layers=layer_depths[1],\n",
    "            num_heads=num_heads[1],\n",
    "            mlp_ratio=mlp_ratios[1],\n",
    "            norm_layer=norm_layers[1],\n",
    "            window_size=window_size,\n",
    "            attention_ratio=attention_ratios[1],\n",
    "            attention_placement='last',\n",
    "            conv_mode=conv_types[1]\n",
    "        )\n",
    "        \n",
    "        self.downsample2 = PatchEmbedding(\n",
    "            patch_size=2, input_channels=embed_dims[1], embedding_dim=embed_dims[2]\n",
    "        )\n",
    "        \n",
    "        self.skip_connection2 = nn.Conv2d(embed_dims[1], embed_dims[1], 1)\n",
    "        \n",
    "        self.encoder_stage3 = TransformerStage(\n",
    "            network_depth=sum(layer_depths),\n",
    "            embed_dim=embed_dims[2],\n",
    "            num_layers=layer_depths[2],\n",
    "            num_heads=num_heads[2],\n",
    "            mlp_ratio=mlp_ratios[2],\n",
    "            norm_layer=norm_layers[2],\n",
    "            window_size=window_size,\n",
    "            attention_ratio=attention_ratios[2],\n",
    "            attention_placement='last',\n",
    "            conv_mode=conv_types[2]\n",
    "        )\n",
    "        \n",
    "        self.upsample1 = PatchReconstruction(\n",
    "            patch_size=2, output_channels=embed_dims[3], embedding_dim=embed_dims[2]\n",
    "        )\n",
    "        \n",
    "        assert embed_dims[1] == embed_dims[3]\n",
    "        self.fusion_layer1 = SelectiveKernelFusion(embed_dims[3])\n",
    "        \n",
    "        self.decoder_stage1 = TransformerStage(\n",
    "            network_depth=sum(layer_depths),\n",
    "            embed_dim=embed_dims[3],\n",
    "            num_layers=layer_depths[3],\n",
    "            num_heads=num_heads[3],\n",
    "            mlp_ratio=mlp_ratios[3],\n",
    "            norm_layer=norm_layers[3],\n",
    "            window_size=window_size,\n",
    "            attention_ratio=attention_ratios[3],\n",
    "            attention_placement='last',\n",
    "            conv_mode=conv_types[3]\n",
    "        )\n",
    "        \n",
    "        self.upsample2 = PatchReconstruction(\n",
    "            patch_size=2, output_channels=embed_dims[4], embedding_dim=embed_dims[3]\n",
    "        )\n",
    "        \n",
    "        assert embed_dims[0] == embed_dims[4]\n",
    "        self.fusion_layer2 = SelectiveKernelFusion(embed_dims[4])\n",
    "        \n",
    "        self.decoder_stage2 = TransformerStage(\n",
    "            network_depth=sum(layer_depths),\n",
    "            embed_dim=embed_dims[4],\n",
    "            num_layers=layer_depths[4],\n",
    "            num_heads=num_heads[4],\n",
    "            mlp_ratio=mlp_ratios[4],\n",
    "            norm_layer=norm_layers[4],\n",
    "            window_size=window_size,\n",
    "            attention_ratio=attention_ratios[4],\n",
    "            attention_placement='last',\n",
    "            conv_mode=conv_types[4]\n",
    "        )\n",
    "\n",
    "        # Final patch reconstruction\n",
    "        self.patch_reconstruction = PatchReconstruction(\n",
    "            patch_size=1, output_channels=output_channels, embedding_dim=embed_dims[4], kernel_size=3)\n",
    "\n",
    "    def adjust_image_size(self, x):\n",
    "        # Ensures the input image size is compatible with the patch size\n",
    "        _, _, height, width = x.size()\n",
    "        pad_height = (self.patch_size - height % self.patch_size) % self.patch_size\n",
    "        pad_width = (self.patch_size - width % self.patch_size) % self.patch_size\n",
    "        x = F.pad(x, (0, pad_width, 0, pad_height), 'reflect')\n",
    "        return x\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = self.encoder_stage1(x)\n",
    "        skip1 = x\n",
    "\n",
    "        x = self.downsample1(x)\n",
    "        x = self.encoder_stage2(x)\n",
    "        skip2 = x\n",
    "\n",
    "        x = self.downsample2(x)\n",
    "        x = self.encoder_stage3(x)\n",
    "        x = self.upsample1(x)\n",
    "\n",
    "        x = self.fusion_layer1([x, self.skip_connection2(skip2)]) + x\n",
    "        x = self.decoder_stage1(x)\n",
    "        x = self.upsample2(x)\n",
    "\n",
    "        x = self.fusion_layer2([x, self.skip_connection1(skip1)]) + x\n",
    "        x = self.decoder_stage2(x)\n",
    "        x = self.patch_reconstruction(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        original_height, original_width = x.shape[2:]\n",
    "        x = self.adjust_image_size(x)\n",
    "\n",
    "        features = self.extract_features(x)\n",
    "        transmission_map, atmospheric_light = torch.split(features, (1, 3), dim=1)\n",
    "\n",
    "        # Dehazing formula: I = J * t + A * (1 - t)\n",
    "        x = transmission_map * x - atmospheric_light + x\n",
    "        x = x[:, :, :original_height, :original_width]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31484f18",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.638191Z",
     "iopub.status.busy": "2025-04-12T13:09:32.637979Z",
     "iopub.status.idle": "2025-04-12T13:09:32.641733Z",
     "shell.execute_reply": "2025-04-12T13:09:32.641121Z"
    },
    "papermill": {
     "duration": 0.015434,
     "end_time": "2025-04-12T13:09:32.642796",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.627362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dehazing_transformer():\n",
    "    return DehazingTransformer(\n",
    "        embed_dims=[24, 48, 96, 48, 24],\n",
    "        mlp_ratios=[2., 4., 4., 2., 2.],\n",
    "        layer_depths=[12, 12, 12, 6, 6],\n",
    "        num_heads=[2, 4, 6, 1, 1],\n",
    "        attention_ratios=[1/4, 1/2, 3/4, 0, 0],\n",
    "        conv_types=['Conv', 'Conv', 'Conv', 'Conv', 'Conv']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f56a8a52",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.663910Z",
     "iopub.status.busy": "2025-04-12T13:09:32.663689Z",
     "iopub.status.idle": "2025-04-12T13:09:32.670810Z",
     "shell.execute_reply": "2025-04-12T13:09:32.670042Z"
    },
    "papermill": {
     "duration": 0.018977,
     "end_time": "2025-04-12T13:09:32.671995",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.653018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvolutionalGuidedFilter(nn.Module):\n",
    "    def __init__(self, radius=1, norm_layer=nn.BatchNorm2d, conv_kernel_size: int = 1):\n",
    "        super(ConvolutionalGuidedFilter, self).__init__()\n",
    "\n",
    "        self.box_filter = nn.Conv2d(\n",
    "            3, 3, kernel_size=3, padding=radius, dilation=radius, bias=False, groups=3\n",
    "        )\n",
    "        self.conv_a = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                6,\n",
    "                32,\n",
    "                kernel_size=conv_kernel_size,\n",
    "                padding=conv_kernel_size // 2,\n",
    "                bias=False,\n",
    "            ),\n",
    "            norm_layer(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                32,\n",
    "                32,\n",
    "                kernel_size=conv_kernel_size,\n",
    "                padding=conv_kernel_size // 2,\n",
    "                bias=False,\n",
    "            ),\n",
    "            norm_layer(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                32,\n",
    "                3,\n",
    "                kernel_size=conv_kernel_size,\n",
    "                padding=conv_kernel_size // 2,\n",
    "                bias=False,\n",
    "            ),\n",
    "        )\n",
    "        self.box_filter.weight.data[...] = 1.0\n",
    "\n",
    "    def forward(self, x_low_res, y_low_res, x_high_res):\n",
    "        _, _, h_lr, w_lr = x_low_res.size()\n",
    "        _, _, h_hr, w_hr = x_high_res.size()\n",
    "\n",
    "        N = self.box_filter(x_low_res.data.new().resize_((1, 3, h_lr, w_lr)).fill_(1.0))\n",
    "        ## mean_x\n",
    "        mean_x = self.box_filter(x_low_res) / N\n",
    "        ## mean_y\n",
    "        mean_y = self.box_filter(y_low_res) / N\n",
    "        ## cov_xy\n",
    "        cov_xy = self.box_filter(x_low_res * y_low_res) / N - mean_x * mean_y\n",
    "        ## var_x\n",
    "        var_x = self.box_filter(x_low_res * x_low_res) / N - mean_x * mean_x\n",
    "\n",
    "        ## A\n",
    "        A = self.conv_a(torch.cat([cov_xy, var_x], dim=1))\n",
    "        ## b\n",
    "        b = mean_y - A * mean_x\n",
    "\n",
    "        ## mean_A; mean_b\n",
    "        mean_A = F.interpolate(A, (h_hr, w_hr), mode=\"bilinear\", align_corners=True)\n",
    "        mean_b = F.interpolate(b, (h_hr, w_hr), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return mean_A * x_high_res + mean_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad09cb0e",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.692884Z",
     "iopub.status.busy": "2025-04-12T13:09:32.692676Z",
     "iopub.status.idle": "2025-04-12T13:09:32.697827Z",
     "shell.execute_reply": "2025-04-12T13:09:32.697235Z"
    },
    "papermill": {
     "duration": 0.016895,
     "end_time": "2025-04-12T13:09:32.699032",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.682137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PixelAttentionLayer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(PixelAttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "                nn.Conv2d(channels, channels // 8, kernel_size=1, padding=0, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channels // 8, 1, kernel_size=1, padding=0, bias=True),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attention_map = self.attention(x)\n",
    "        return x * attention_map\n",
    "\n",
    "class ChannelAttentionLayer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ChannelAttentionLayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.attention = nn.Sequential(\n",
    "                nn.Conv2d(channels, channels // 8, kernel_size=1, padding=0, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channels // 8, channels, kernel_size=1, padding=0, bias=True),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pooled = self.avg_pool(x)\n",
    "        attention_map = self.attention(pooled)\n",
    "        return x * attention_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1620cd08",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.720414Z",
     "iopub.status.busy": "2025-04-12T13:09:32.720218Z",
     "iopub.status.idle": "2025-04-12T13:09:32.726789Z",
     "shell.execute_reply": "2025-04-12T13:09:32.726190Z"
    },
    "papermill": {
     "duration": 0.018495,
     "end_time": "2025-04-12T13:09:32.727852",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.709357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SuperResolutionDilationBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_dense_layers, growth_rate):\n",
    "        super(SuperResolutionDilationBlock, self).__init__()\n",
    "\n",
    "        self.split_channels = in_channels // 4\n",
    "        kernel_size = 3\n",
    "\n",
    "        # Dilated convolutions with increasing dilation rates\n",
    "        self.conv1 = nn.Conv2d(self.split_channels, self.split_channels, kernel_size=kernel_size, padding=1, dilation=1)\n",
    "        self.conv2 = nn.Conv2d(self.split_channels * 2, self.split_channels, kernel_size=kernel_size, padding=2, dilation=2)\n",
    "        self.conv3 = nn.Conv2d(self.split_channels * 3, self.split_channels, kernel_size=kernel_size, padding=4, dilation=4)\n",
    "        self.conv4 = nn.Conv2d(self.split_channels * 4, self.split_channels, kernel_size=kernel_size, padding=8, dilation=8)\n",
    "\n",
    "        # Attention mechanisms\n",
    "        self.channel_attention = ChannelAttentionLayer(in_channels)\n",
    "        self.pixel_attention = PixelAttentionLayer(in_channels)\n",
    "\n",
    "        # Final 1x1 convolution for feature fusion\n",
    "        self.conv_1x1 = nn.Conv2d(in_channels, in_channels, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split input into 4 equal parts along channel dimension\n",
    "        split_features = torch.split(x, self.split_channels, dim=1)\n",
    "\n",
    "        x0 = F.relu(self.conv1(split_features[0]))\n",
    "        tmp = torch.cat((split_features[1], x0), dim=1)\n",
    "        x1 = F.relu(self.conv2(tmp))\n",
    "\n",
    "        tmp = torch.cat((split_features[2], x0, x1), dim=1)\n",
    "        x2 = F.relu(self.conv3(tmp))\n",
    "\n",
    "        tmp = torch.cat((split_features[3], x0, x1, x2), dim=1)\n",
    "        x3 = F.relu(self.conv4(tmp))\n",
    "\n",
    "        # Concatenate all outputs\n",
    "        merged_features = torch.cat((x0, x1, x2, x3), dim=1)\n",
    "\n",
    "        # Apply 1x1 convolution for feature refinement\n",
    "        out = self.conv_1x1(merged_features)\n",
    "\n",
    "        # Apply attention mechanisms\n",
    "        out = self.channel_attention(out)\n",
    "        out = self.pixel_attention(out)\n",
    "\n",
    "        # Residual connection\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ffabc14",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.748469Z",
     "iopub.status.busy": "2025-04-12T13:09:32.748271Z",
     "iopub.status.idle": "2025-04-12T13:09:32.752103Z",
     "shell.execute_reply": "2025-04-12T13:09:32.751502Z"
    },
    "papermill": {
     "duration": 0.015456,
     "end_time": "2025-04-12T13:09:32.753293",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.737837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdaptiveInstanceNormalization(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(AdaptiveInstanceNormalization, self).__init__()\n",
    "\n",
    "        # Learnable scaling factors\n",
    "        self.scale_x = nn.Parameter(torch.tensor(1.0))  # Identity scaling\n",
    "        self.scale_norm = nn.Parameter(torch.tensor(0.0))  # Initially no effect\n",
    "\n",
    "        # Instance normalization layer with affine transformation enabled\n",
    "        self.instance_norm = nn.InstanceNorm2d(num_channels, momentum=0.999, eps=0.001, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        normalized_x = self.instance_norm(x)\n",
    "        return self.scale_x * x + self.scale_norm * normalized_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e199c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.774134Z",
     "iopub.status.busy": "2025-04-12T13:09:32.773936Z",
     "iopub.status.idle": "2025-04-12T13:09:32.779687Z",
     "shell.execute_reply": "2025-04-12T13:09:32.779130Z"
    },
    "papermill": {
     "duration": 0.01754,
     "end_time": "2025-04-12T13:09:32.780956",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.763416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepGuidedNetwork(nn.Module):\n",
    "    def __init__(self, radius=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Adaptive Normalization for Guided Filtering\n",
    "        norm = AdaptiveInstanceNormalization\n",
    "        kernel_size = 3\n",
    "        depth_rate = 16\n",
    "        in_channels = 3\n",
    "        num_dense_layer = 4\n",
    "        growth_rate = 16\n",
    "\n",
    "        # Initial convolution layers\n",
    "        self.conv_in = nn.Conv2d(in_channels, depth_rate, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
    "        self.conv_out = nn.Conv2d(depth_rate, in_channels, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
    "\n",
    "        # Residual Dense Blocks (RDBs)\n",
    "        self.rdb1 = SuperResolutionDilationBlock(depth_rate, num_dense_layer, growth_rate)\n",
    "        self.rdb2 = SuperResolutionDilationBlock(depth_rate, num_dense_layer, growth_rate)\n",
    "        self.rdb3 = SuperResolutionDilationBlock(depth_rate, num_dense_layer, growth_rate)\n",
    "        self.rdb4 = SuperResolutionDilationBlock(depth_rate, num_dense_layer, growth_rate)\n",
    "\n",
    "        # Guided Filter & Dehazing Transformer\n",
    "        self.guided_filter = ConvolutionalGuidedFilter(radius, norm_layer=norm)\n",
    "        self.dehaze_network = build_dehazing_transformer()\n",
    "\n",
    "        # Downsampling & Upsampling Layers\n",
    "        self.downsample = nn.Upsample(scale_factor=0.5, mode=\"bilinear\", align_corners=True)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "    def forward(self, x_hr):\n",
    "        # Low-resolution processing\n",
    "        x_lr = self.downsample(x_hr)\n",
    "\n",
    "        # Detail extraction through Residual Dense Blocks\n",
    "        y_features = self.conv_in(x_lr)\n",
    "        y_features = self.rdb1(y_features)\n",
    "        y_features = self.rdb2(y_features)\n",
    "        y_features = self.rdb3(y_features)\n",
    "        y_features = self.rdb4(y_features)\n",
    "        y_detail = self.conv_out(y_features)\n",
    "\n",
    "        y_base_hr = self.upsample(y_detail)\n",
    "        y_lr = y_base_hr\n",
    "        # Final guided filtering refinement\n",
    "        refined_output = self.guided_filter(x_lr, y_lr, x_hr)\n",
    "        \n",
    "        return refined_output, y_base_hr\n",
    "\n",
    "class DeepGuidedNetwork(nn.Module):\n",
    "    def __init__(self, radius=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Adaptive Normalization for Guided Filtering\n",
    "        norm = AdaptiveInstanceNormalization\n",
    "        kernel_size = 3\n",
    "        depth_rate = 16\n",
    "        in_channels = 3\n",
    "        num_dense_layer = 4\n",
    "        growth_rate = 16\n",
    "\n",
    "        # Initial convolution layers\n",
    "        self.conv_in = nn.Conv2d(in_channels, depth_rate, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
    "        self.conv_out = nn.Conv2d(depth_rate, in_channels, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
    "\n",
    "        # Residual Dense Blocks (RDBs)\n",
    "        self.rdb1 = SuperResolutionDilationBlock(depth_rate, num_dense_layer, growth_rate)\n",
    "        self.rdb2 = SuperResolutionDilationBlock(depth_rate, num_dense_layer, growth_rate)\n",
    "        self.rdb3 = SuperResolutionDilationBlock(depth_rate, num_dense_layer, growth_rate)\n",
    "        self.rdb4 = SuperResolutionDilationBlock(depth_rate, num_dense_layer, growth_rate)\n",
    "\n",
    "        # Guided Filter & Dehazing Transformer\n",
    "        self.guided_filter = ConvolutionalGuidedFilter(radius, norm_layer=norm)\n",
    "        self.dehaze_network = build_dehazing_transformer()\n",
    "\n",
    "        # Downsampling & Upsampling Layers\n",
    "        self.downsample = nn.Upsample(scale_factor=0.5, mode=\"bilinear\", align_corners=True)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "    def forward(self, x_hr):\n",
    "        x_lr = self.downsample(x_hr)\n",
    "    \n",
    "        # Initial conv\n",
    "        y_features = self.conv_in(x_lr)\n",
    "    \n",
    "        # RDBs + collect features\n",
    "        feat1 = self.rdb1(y_features)\n",
    "        feat2 = self.rdb2(feat1)\n",
    "        feat3 = self.rdb3(feat2)\n",
    "        feat4 = self.rdb4(feat3)\n",
    "        y_detail = self.conv_out(feat4)\n",
    "    \n",
    "        # Base image\n",
    "        y_base = self.dehaze_network(x_lr)\n",
    "    \n",
    "        # Combine\n",
    "        y_lr = y_base + y_detail\n",
    "        y_base_hr = self.upsample(y_base)\n",
    "    \n",
    "        # Guided output\n",
    "        refined_output = self.guided_filter(x_lr, y_lr, x_hr)\n",
    "    \n",
    "        return refined_output, y_base_hr, [feat1, feat2, feat3, feat4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be2bcb78",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.831350Z",
     "iopub.status.busy": "2025-04-12T13:09:32.831128Z",
     "iopub.status.idle": "2025-04-12T13:09:32.834448Z",
     "shell.execute_reply": "2025-04-12T13:09:32.833836Z"
    },
    "papermill": {
     "duration": 0.015224,
     "end_time": "2025-04-12T13:09:32.835610",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.820386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_crop_size(crop_size_str):\n",
    "    try:\n",
    "        return [int(x.strip()) for x in crop_size_str.split(',')]\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Invalid crop size format: '{crop_size_str}'. Expected comma-separated integers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15eb5760",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.856520Z",
     "iopub.status.busy": "2025-04-12T13:09:32.856323Z",
     "iopub.status.idle": "2025-04-12T13:09:32.865023Z",
     "shell.execute_reply": "2025-04-12T13:09:32.864437Z"
    },
    "papermill": {
     "duration": 0.020548,
     "end_time": "2025-04-12T13:09:32.866232",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.845684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from random import randrange\n",
    "\n",
    "class TrainData(Dataset):\n",
    "    def __init__(self, crop_size, hazeeffected_images_dir, hazefree_images_dir):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- Ensure valid file extensions --- #\n",
    "        valid_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
    "        hazy_data = [\n",
    "            f for f in glob.glob(os.path.join(hazeeffected_images_dir, \"*.*\"))\n",
    "            if f.lower().endswith(valid_extensions)\n",
    "        ]\n",
    "\n",
    "        if not hazy_data:\n",
    "            raise ValueError(f\"No valid images found in {hazeeffected_images_dir}\")\n",
    "\n",
    "        self.hazeeffected_images_dir = hazeeffected_images_dir\n",
    "        self.hazefree_images_dir = hazefree_images_dir\n",
    "\n",
    "        self.haze_names = []\n",
    "        self.gt_names = []\n",
    "        \n",
    "        for h_image in hazy_data:\n",
    "            filename = os.path.basename(h_image)\n",
    "            haze_path = os.path.join(self.hazeeffected_images_dir, filename)\n",
    "            gt_path = os.path.join(self.hazefree_images_dir, filename)\n",
    "\n",
    "            if not os.path.exists(gt_path):\n",
    "                print(f\"Warning: Ground-truth missing for {filename}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            self.haze_names.append(haze_path)\n",
    "            self.gt_names.append(gt_path)\n",
    "\n",
    "        if not self.haze_names:\n",
    "            raise ValueError(\"No matching ground-truth images found.\")\n",
    "\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "    def get_images(self, index):\n",
    "        crop_width, crop_height = self.crop_size\n",
    "        haze_name = self.haze_names[index]\n",
    "        gt_name = self.gt_names[index]\n",
    "\n",
    "        try:\n",
    "            haze_img = Image.open(haze_name).convert('RGB')\n",
    "            gt_img = Image.open(gt_name).convert('RGB')\n",
    "        except UnidentifiedImageError:\n",
    "            raise ValueError(f\"Invalid image format: {haze_name} or {gt_name}\")\n",
    "\n",
    "        width, height = haze_img.size\n",
    "\n",
    "        # --- Handle small images --- #\n",
    "        if width < crop_width or height < crop_height:\n",
    "            raise ValueError(f\"Image too small for cropping: {haze_name}\")\n",
    "\n",
    "        # --- Random crop --- #\n",
    "        x, y = randrange(0, width - crop_width + 1), randrange(0, height - crop_height + 1)\n",
    "        haze_crop_img = haze_img.crop((x, y, x + crop_width, y + crop_height))\n",
    "        gt_crop_img = gt_img.crop((x, y, x + crop_width, y + crop_height))\n",
    "\n",
    "        # --- Transform to tensor --- #\n",
    "        transform_haze = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        transform_gt = Compose([ToTensor()])\n",
    "        haze = transform_haze(haze_crop_img)\n",
    "        gt = transform_gt(gt_crop_img)\n",
    "\n",
    "        # --- Check channels --- #\n",
    "        if haze.shape[0] != 3 or gt.shape[0] != 3:\n",
    "            raise ValueError(f\"Invalid image channels: {haze_name}\")\n",
    "\n",
    "        return haze, gt\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.get_images(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.haze_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "077f0d02",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.887340Z",
     "iopub.status.busy": "2025-04-12T13:09:32.887117Z",
     "iopub.status.idle": "2025-04-12T13:09:32.896753Z",
     "shell.execute_reply": "2025-04-12T13:09:32.895979Z"
    },
    "papermill": {
     "duration": 0.021732,
     "end_time": "2025-04-12T13:09:32.898060",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.876328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from random import randrange, shuffle\n",
    "\n",
    "class HazeDataset(Dataset):\n",
    "    def __init__(self, crop_size, hazeeffected_images_dir, hazefree_images_dir, split=\"train\", split_ratio=0.8):\n",
    "        \"\"\"\n",
    "        Dataset class for handling both training and validation dynamically.\n",
    "        \n",
    "        Args:\n",
    "            crop_size (tuple): (width, height) of the random crop.\n",
    "            hazeeffected_images_dir (str): Directory for hazy images.\n",
    "            hazefree_images_dir (str): Directory for ground-truth images.\n",
    "            split (str): \"train\" or \"valid\" (determines data split).\n",
    "            split_ratio (float): Percentage of images to use for training (default 80% train, 20% validation).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- Ensure valid file extensions --- #\n",
    "        valid_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
    "        hazy_data = [\n",
    "            f for f in glob.glob(os.path.join(hazeeffected_images_dir, \"*.*\"))\n",
    "            if f.lower().endswith(valid_extensions)\n",
    "        ]\n",
    "\n",
    "        if not hazy_data:\n",
    "            raise ValueError(f\"No valid images found in {hazeeffected_images_dir}\")\n",
    "\n",
    "        # # --- Sort and shuffle to ensure random split --- #\n",
    "        hazy_data.sort()\n",
    "        # shuffle(hazy_data)  \n",
    "\n",
    "        # --- Split into train and validation --- #\n",
    "        split_idx = int(len(hazy_data) * split_ratio)\n",
    "        if split == \"train\":\n",
    "            hazy_data = hazy_data[:split_idx]\n",
    "        else:  # \"valid\"\n",
    "            hazy_data = hazy_data[split_idx:]\n",
    "\n",
    "        self.haze_names = []\n",
    "        self.gt_names = []\n",
    "        \n",
    "        for h_image in hazy_data:\n",
    "            filename = os.path.basename(h_image)\n",
    "            haze_path = os.path.join(hazeeffected_images_dir, filename)\n",
    "            gt_path = os.path.join(hazefree_images_dir, filename)\n",
    "\n",
    "            if not os.path.exists(gt_path):\n",
    "                print(f\"Warning: Ground-truth missing for {filename}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            self.haze_names.append(haze_path)\n",
    "            self.gt_names.append(gt_path)\n",
    "\n",
    "        if not self.haze_names:\n",
    "            raise ValueError(\"No matching ground-truth images found.\")\n",
    "\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "    def get_images(self, index):\n",
    "        crop_width, crop_height = self.crop_size\n",
    "        haze_name = self.haze_names[index]\n",
    "        gt_name = self.gt_names[index]\n",
    "\n",
    "        try:\n",
    "            haze_img = Image.open(haze_name).convert('RGB')\n",
    "            gt_img = Image.open(gt_name).convert('RGB')\n",
    "        except UnidentifiedImageError:\n",
    "            raise ValueError(f\"Invalid image format: {haze_name} or {gt_name}\")\n",
    "\n",
    "        width, height = haze_img.size\n",
    "\n",
    "        # --- Handle small images --- #\n",
    "        if width < crop_width or height < crop_height:\n",
    "            raise ValueError(f\"Image too small for cropping: {haze_name}\")\n",
    "\n",
    "        # --- Random crop --- #\n",
    "        x, y = randrange(0, width - crop_width + 1), randrange(0, height - crop_height + 1)\n",
    "        haze_crop_img = haze_img.crop((x, y, x + crop_width, y + crop_height))\n",
    "        gt_crop_img = gt_img.crop((x, y, x + crop_width, y + crop_height))\n",
    "\n",
    "        # --- Transform to tensor --- #\n",
    "        transform_haze = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        transform_gt = Compose([ToTensor()])\n",
    "        haze = transform_haze(haze_crop_img)\n",
    "        gt = transform_gt(gt_crop_img)\n",
    "\n",
    "        # --- Check channels --- #\n",
    "        if haze.shape[0] != 3 or gt.shape[0] != 3:\n",
    "            raise ValueError(f\"Invalid image channels: {haze_name}\")\n",
    "\n",
    "        return haze, gt\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.get_images(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.haze_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d57cbb",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 0.010053,
     "end_time": "2025-04-12T13:09:32.918333",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.908280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0c63e44",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.940798Z",
     "iopub.status.busy": "2025-04-12T13:09:32.940548Z",
     "iopub.status.idle": "2025-04-12T13:09:32.944548Z",
     "shell.execute_reply": "2025-04-12T13:09:32.943765Z"
    },
    "papermill": {
     "duration": 0.017326,
     "end_time": "2025-04-12T13:09:32.945817",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.928491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_psnr(dehaze, gt):\n",
    "    \"\"\"\n",
    "    Compute PSNR (Peak Signal-to-Noise Ratio) between dehazed and ground truth images.\n",
    "\n",
    "    Args:\n",
    "        dehaze (torch.Tensor): Dehazed image tensor (B, C, H, W)\n",
    "        gt (torch.Tensor): Ground truth image tensor (B, C, H, W)\n",
    "\n",
    "    Returns:\n",
    "        List[float]: PSNR values for each image in the batch.\n",
    "    \"\"\"\n",
    "    mse = F.mse_loss(dehaze, gt, reduction='none').mean(dim=[1, 2, 3])  # Compute MSE per image\n",
    "    intensity_max = 1.0\n",
    "\n",
    "    # Compute PSNR safely, avoiding division by zero and extreme values\n",
    "    psnr_list = [10.0 * log10(intensity_max / max(mse_val.item(), 1e-6)) for mse_val in mse]\n",
    "\n",
    "    return psnr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d89b5f82",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:32.966699Z",
     "iopub.status.busy": "2025-04-12T13:09:32.966474Z",
     "iopub.status.idle": "2025-04-12T13:09:35.295719Z",
     "shell.execute_reply": "2025-04-12T13:09:35.294691Z"
    },
    "papermill": {
     "duration": 2.341767,
     "end_time": "2025-04-12T13:09:35.297645",
     "exception": false,
     "start_time": "2025-04-12T13:09:32.955878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "\n",
    "# Define SSIM metric\n",
    "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0, reduction='none')\n",
    "\n",
    "def to_ssim(dehaze: torch.Tensor, gt: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute SSIM directly on the GPU using torchmetrics.\n",
    "\n",
    "    Args:\n",
    "        dehaze (torch.Tensor): Dehazed image tensor (B, C, H, W)\n",
    "        gt (torch.Tensor): Ground truth image tensor (B, C, H, W)\n",
    "\n",
    "    Returns:\n",
    "        List[float]: SSIM values for each image in the batch.\n",
    "    \"\"\"\n",
    "    ssim_values = ssim_metric(dehaze, gt)  # Shape: [B]\n",
    "    # print(\"1\",ssim_values)\n",
    "    # print(\"2\",[ssim_values])\n",
    "    ssim_values = ssim_values.tolist() \n",
    "    # print(type(ssim_values))\n",
    "    if isinstance(ssim_values, float):  # Correct way to check for a float\n",
    "        return [ssim_values]  # Convert single float to a list\n",
    "    return ssim_values  # Otherwise, return as is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68baa4b8",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.323941Z",
     "iopub.status.busy": "2025-04-12T13:09:35.323267Z",
     "iopub.status.idle": "2025-04-12T13:09:35.491577Z",
     "shell.execute_reply": "2025-04-12T13:09:35.489819Z"
    },
    "papermill": {
     "duration": 0.183935,
     "end_time": "2025-04-12T13:09:35.493308",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.309373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0026210546493530273]\n"
     ]
    }
   ],
   "source": [
    "# Test with a dummy tensor\n",
    "dehaze = torch.rand(1, 3, 360, 360)  # Random batch of images\n",
    "gt = torch.rand(1, 3, 360, 360)  # Random ground truth images\n",
    "\n",
    "ssim_scores = to_ssim(dehaze, gt)\n",
    "print(ssim_scores)  # Should print a list of 6 SSIM values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8abd0497",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.515739Z",
     "iopub.status.busy": "2025-04-12T13:09:35.515396Z",
     "iopub.status.idle": "2025-04-12T13:09:35.521009Z",
     "shell.execute_reply": "2025-04-12T13:09:35.520205Z"
    },
    "papermill": {
     "duration": 0.018069,
     "end_time": "2025-04-12T13:09:35.522246",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.504177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validationB(net, val_data_loader, device, category, save_tag=False):\n",
    "    \"\"\"\n",
    "    :param net: Your deep learning model\n",
    "    :param val_data_loader: validation loader\n",
    "    :param device: GPU/CPU device\n",
    "    :param category: dataset type (indoor/outdoor)\n",
    "    :param save_tag: whether to save images\n",
    "    :return: average PSNR & SSIM values\n",
    "    \"\"\"\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    \n",
    "    for batch_id, val_data in enumerate(val_data_loader):\n",
    "        with torch.no_grad():\n",
    "            haze, gt = val_data\n",
    "            haze, gt = haze.to(device), gt.to(device)\n",
    "            dehaze, _ = net(haze)\n",
    "\n",
    "        # --- Compute PSNR & SSIM --- #\n",
    "        batch_psnr = to_psnr(dehaze, gt)  # This returns a list\n",
    "        # print(batch_psnr)\n",
    "        batch_ssim = to_ssim(dehaze, gt)  # This returns a list\n",
    "        # print(batch_ssim)\n",
    "\n",
    "        psnr_list.extend(batch_psnr)  # Flatten the list\n",
    "        ssim_list.extend(batch_ssim)  # Flatten the list\n",
    "\n",
    "    # --- Ensure lists are not empty to avoid division by zero --- #\n",
    "    avr_psnr = sum(psnr_list) / len(psnr_list) if psnr_list else 0.0\n",
    "    avr_ssim = sum(ssim_list) / len(ssim_list) if ssim_list else 0.0\n",
    "\n",
    "    return avr_psnr, avr_ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583ea28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.545410Z",
     "iopub.status.busy": "2025-04-12T13:09:35.545170Z",
     "iopub.status.idle": "2025-04-12T13:09:35.549871Z",
     "shell.execute_reply": "2025-04-12T13:09:35.549055Z"
    },
    "papermill": {
     "duration": 0.01909,
     "end_time": "2025-04-12T13:09:35.551459",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.532369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation_sr(net, sr_val_loader, device):\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    for lr, hr in sr_val_loader:\n",
    "        with torch.no_grad():\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            sr_out, _ = net(lr, sr = False)\n",
    "        psnr_list.extend(to_psnr(sr_out, hr))\n",
    "        ssim_list.extend(to_ssim(sr_out, hr))\n",
    "\n",
    "    avr_psnr = sum(psnr_list) / len(psnr_list) if psnr_list else 0.0\n",
    "    avr_ssim = sum(ssim_list) / len(ssim_list) if ssim_list else 0.0\n",
    "    return avr_psnr, avr_ssim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9c929",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 0.009925,
     "end_time": "2025-04-12T13:09:35.578339",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.568414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad82e559",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.599620Z",
     "iopub.status.busy": "2025-04-12T13:09:35.599367Z",
     "iopub.status.idle": "2025-04-12T13:09:35.602898Z",
     "shell.execute_reply": "2025-04-12T13:09:35.602110Z"
    },
    "papermill": {
     "duration": 0.016023,
     "end_time": "2025-04-12T13:09:35.604481",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.588458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# old_val_psnr, old_val_ssim = validationB(net, val_data_loader, device, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2f6bd1c",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.633300Z",
     "iopub.status.busy": "2025-04-12T13:09:35.633075Z",
     "iopub.status.idle": "2025-04-12T13:09:35.636077Z",
     "shell.execute_reply": "2025-04-12T13:09:35.635234Z"
    },
    "papermill": {
     "duration": 0.015183,
     "end_time": "2025-04-12T13:09:35.637575",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.622392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# psnr, ssim = validationB(net, val_data_loader, device, category)\n",
    "# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # psnr, ssim = validationB(model, val_loader, device, \"indoor\", save_tag=True)\n",
    "# print(f\"Validation PSNR: {psnr:.2f}, SSIM: {ssim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a30f73e",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.666647Z",
     "iopub.status.busy": "2025-04-12T13:09:35.666421Z",
     "iopub.status.idle": "2025-04-12T13:09:35.675158Z",
     "shell.execute_reply": "2025-04-12T13:09:35.674352Z"
    },
    "papermill": {
     "duration": 0.021172,
     "end_time": "2025-04-12T13:09:35.676615",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.655443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9051d2130a9440e2aede3d71e4338319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Execution Env:', options=('local', 'kaggle'), value='local')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execution_env_widget = widgets.Dropdown(options=['local', 'kaggle'], value='local', description='Execution Env:')\n",
    "display(execution_env_widget)\n",
    "\n",
    "if os.path.exists('/kaggle'):\n",
    "    execution_env_widget.value = 'kaggle' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e483911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.707435Z",
     "iopub.status.busy": "2025-04-12T13:09:35.707186Z",
     "iopub.status.idle": "2025-04-12T13:09:35.748473Z",
     "shell.execute_reply": "2025-04-12T13:09:35.747595Z"
    },
    "papermill": {
     "duration": 0.054368,
     "end_time": "2025-04-12T13:09:35.750507",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.696139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71d7b68439941bc8ba5d78fb72cae95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0001, description='Learning Rate:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51306f8eca8d44edb7f993f466bb73f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='128,128', description='Crop Size:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a12c3d6b134d87bb52fdd4c81a93c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=6, description='Train Batch Size:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20108624275648efaf8274f5be54c73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='Version:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58a5f34d4d94c37a3e32b8e98d4e9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=16, description='Growth Rate:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f71c04b7664419284ec27275ec9bb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.04, description='Lambda Loss:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4808eb4bd4f04957b74e39a5cc34fb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=2, description='Val Batch Size:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da45365861b644abb96d8a49950814cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Category:', index=2, options=('indoor', 'outdoor', 'reside', 'nh'), value='reside')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyper-parameters set:\n",
      "learning_rate: 0.0001\n",
      "crop_size: [128, 128]\n",
      "train_batch_size: 6\n",
      "version: 0\n",
      "growth_rate: 16\n",
      "lambda_loss: 0.04\n",
      "val_batch_size: 2\n",
      "category: reside\n",
      "execution_env: kaggle\n",
      "\n",
      "Final dataset paths:\n",
      "Training directory: /kaggle/input/reside6k/RESIDE-6K/train\n",
      "Validation directory: /kaggle/input/reside6k/RESIDE-6K/train\n",
      "Number of epochs: 85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Create widgets for each hyper-parameter ---\n",
    "learning_rate_widget = widgets.FloatText(value=1e-4, description='Learning Rate:')\n",
    "crop_size_widget = widgets.Text(value='128,128', description='Crop Size:')\n",
    "train_batch_size_widget = widgets.IntText(value=6, description='Train Batch Size:')\n",
    "version_widget = widgets.IntText(value=0, description='Version:')\n",
    "growth_rate_widget = widgets.IntText(value=16, description='Growth Rate:')\n",
    "lambda_loss_widget = widgets.FloatText(value=0.04, description='Lambda Loss:')\n",
    "val_batch_size_widget = widgets.IntText(value=2, description='Val Batch Size:')\n",
    "category_widget = widgets.Dropdown(options=['indoor', 'outdoor', 'reside', 'nh'], value='reside', description='Category:')\n",
    "\n",
    "# --- Display the widgets ---\n",
    "display(\n",
    "    learning_rate_widget, crop_size_widget, train_batch_size_widget, version_widget,\n",
    "    growth_rate_widget, lambda_loss_widget, \n",
    "    val_batch_size_widget, category_widget\n",
    ")\n",
    "\n",
    "# --- Function to parse crop size ---\n",
    "def parse_crop_size(crop_size_str):\n",
    "    return [int(x) for x in crop_size_str.split(',')]\n",
    "\n",
    "# --- Assign the widget values to variables ---\n",
    "learning_rate = learning_rate_widget.value\n",
    "crop_size = parse_crop_size(crop_size_widget.value)\n",
    "train_batch_size = train_batch_size_widget.value\n",
    "version = version_widget.value\n",
    "growth_rate = growth_rate_widget.value\n",
    "lambda_loss = lambda_loss_widget.value\n",
    "val_batch_size = val_batch_size_widget.value\n",
    "category = category_widget.value\n",
    "\n",
    "execution_env = execution_env_widget.value  # Local or Kaggle\n",
    "\n",
    "\n",
    "print('\\nHyper-parameters set:')\n",
    "print(f'learning_rate: {learning_rate}')\n",
    "print(f'crop_size: {crop_size}')\n",
    "print(f'train_batch_size: {train_batch_size}')\n",
    "print(f'version: {version}')\n",
    "print(f'growth_rate: {growth_rate}')\n",
    "print(f'lambda_loss: {lambda_loss}')\n",
    "print(f'val_batch_size: {val_batch_size}')\n",
    "print(f'category: {category}')\n",
    "print(f'execution_env: {execution_env}')\n",
    "\n",
    "# --- Set category-specific hyper-parameters ---\n",
    "if category == 'indoor':\n",
    "    num_epochs = 1500\n",
    "    train_data_dir = './data/train/indoor/'\n",
    "    val_data_dir = './data/test/SOTS/indoor/'\n",
    "elif category == 'outdoor':\n",
    "    num_epochs = 10\n",
    "    train_data_dir = './data/train/outdoor/'\n",
    "    val_data_dir = './data/test/SOTS/outdoor/'\n",
    "elif category == 'reside':\n",
    "    num_epochs = 85\n",
    "    train_data_dir = '/kaggle/input/reside6k/RESIDE-6K/train'\n",
    "    val_data_dir = '/kaggle/input/reside6k/RESIDE-6K/train'\n",
    "    test_data_dir = '/kaggle/input/reside6k/RESIDE-6K/test'\n",
    "elif category == 'nh':\n",
    "    num_epochs = 50\n",
    "    train_data_dir = '/Volumes/S/dev/project/code/Aphase/Dehaze_2/data/NH-Haze_Dense-Haze_datasets/NH-HAZE-T/train/hazy'\n",
    "    val_data_dir = '/Volumes/S/dev/project/code/Aphase/Dehaze_2/data/NH-Haze_Dense-Haze_datasets/NH-HAZE-T/train/GT'\n",
    "else:\n",
    "    raise Exception('Wrong image category. Set it to indoor or outdoor for RESIDE dataset.')\n",
    "\n",
    "# --- Adjust paths based on execution environment ---\n",
    "# if execution_env == 'kaggle':\n",
    "    # train_data_dir = '/kaggle/input/reside-dataset/' + train_data_dir.strip('./')\n",
    "    # val_data_dir = '/kaggle/input/reside-dataset/' + val_data_dir.strip('./')\n",
    "    # train_data_dir = '/kaggle/input/nh-dense-haze/NH-HAZE-T/NH-HAZE-T'\n",
    "    # val_data_dir = '/kaggle/input/nh-dense-haze/NH-HAZE-V/NH-HAZE-V' \n",
    "    # train_data_dir = '/kaggle/input/o-haze/O-HAZY/hazy'\n",
    "    # val_data_dir = '/kaggle/input/o-haze/O-HAZY/GT' \n",
    "print('\\nFinal dataset paths:')\n",
    "print(f'Training directory: {train_data_dir}')\n",
    "print(f'Validation directory: {val_data_dir}')\n",
    "print(f'Number of epochs: {num_epochs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "decd7d88",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.811783Z",
     "iopub.status.busy": "2025-04-12T13:09:35.811411Z",
     "iopub.status.idle": "2025-04-12T13:09:35.815702Z",
     "shell.execute_reply": "2025-04-12T13:09:35.814909Z"
    },
    "papermill": {
     "duration": 0.017958,
     "end_time": "2025-04-12T13:09:35.817103",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.799145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hazeeffected_images_dir_train = f\"{train_data_dir}/IN\"\n",
    "hazeeffected_images_dir_train = f\"{train_data_dir}/hazy\"\n",
    "hazefree_images_dir_train = f\"{train_data_dir}/GT\"\n",
    "\n",
    "# hazeeffected_images_dir_valid = f\"{val_data_dir}/IN\"\n",
    "hazeeffected_images_dir_valid = f\"{val_data_dir}/hazy\"\n",
    "hazefree_images_dir_valid = f\"{val_data_dir}/GT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462fa9c",
   "metadata": {
    "papermill": {
     "duration": 0.011082,
     "end_time": "2025-04-12T13:09:35.839407",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.828325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cecd2b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.862811Z",
     "iopub.status.busy": "2025-04-12T13:09:35.862484Z",
     "iopub.status.idle": "2025-04-12T13:09:35.865779Z",
     "shell.execute_reply": "2025-04-12T13:09:35.865067Z"
    },
    "papermill": {
     "duration": 0.016364,
     "end_time": "2025-04-12T13:09:35.867068",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.850704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52fc3d16",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.890985Z",
     "iopub.status.busy": "2025-04-12T13:09:35.890677Z",
     "iopub.status.idle": "2025-04-12T13:09:35.894624Z",
     "shell.execute_reply": "2025-04-12T13:09:35.893883Z"
    },
    "papermill": {
     "duration": 0.017253,
     "end_time": "2025-04-12T13:09:35.895882",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.878629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import shutil\n",
    "\n",
    "# hazeeffected_images_dir_train = f\"{train_data_dir}/IN\"\n",
    "# hazefree_images_dir_train = f\"{train_data_dir}/GT\"\n",
    "\n",
    "# hazeeffected_images_dir_valid = f\"{val_data_dir}/IN\"\n",
    "# hazefree_images_dir_valid = f\"{val_data_dir}/GT\"\n",
    "\n",
    "# # Create validation directories if they don't exist\n",
    "# os.makedirs(hazeeffected_images_dir_valid, exist_ok=True)\n",
    "# os.makedirs(hazefree_images_dir_valid, exist_ok=True)\n",
    "\n",
    "# # List all hazy and clean images\n",
    "# hazy_images = sorted(glob.glob(f\"{hazeeffected_images_dir_train}/*\"))\n",
    "# clean_images = sorted(glob.glob(f\"{hazefree_images_dir_train}/*\"))\n",
    "\n",
    "# # Ensure matching hazy-clean pairs\n",
    "# assert len(hazy_images) == len(clean_images), \"Mismatch in hazy and clean images count!\"\n",
    "\n",
    "# # Shuffle while keeping the hazy-clean correspondence\n",
    "# paired_images = list(zip(hazy_images, clean_images))\n",
    "# # random.shuffle(paired_images)\n",
    "\n",
    "# # Define split ratio (e.g., 80% train, 20% validation)\n",
    "# split_ratio = 0.8\n",
    "# split_idx = int(len(paired_images) * split_ratio)\n",
    "\n",
    "# # Split into train and validation\n",
    "# train_pairs = paired_images[:split_idx]\n",
    "# valid_pairs = paired_images[split_idx:]\n",
    "\n",
    "# # Move validation images\n",
    "# for hazy_path, clean_path in valid_pairs:\n",
    "#     shutil.move(hazy_path, hazeeffected_images_dir_valid)\n",
    "#     shutil.move(clean_path, hazefree_images_dir_valid)\n",
    "\n",
    "# print(f\"Moved {len(valid_pairs)} image pairs to validation set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5559814",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.919114Z",
     "iopub.status.busy": "2025-04-12T13:09:35.918810Z",
     "iopub.status.idle": "2025-04-12T13:09:35.922120Z",
     "shell.execute_reply": "2025-04-12T13:09:35.921379Z"
    },
    "papermill": {
     "duration": 0.016445,
     "end_time": "2025-04-12T13:09:35.923418",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.906973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # hazeeffected_images_dir = '/Volumes/S/dev/project/code/Aphase/Dehaze_2/data/NH-Haze_Dense-Haze_datasets/NH-HAZE-T/train/hazy'\n",
    "# # hazefree_images_dir = '/Volumes/S/dev/project/code/Aphase/Dehaze_2/data/NH-Haze_Dense-Haze_datasets/NH-HAZE-T/train/GT'\n",
    "# # hazeeffected_images_dir = '/kaggle/input/o-haze/O-HAZY/hazy'\n",
    "# # hazefree_images_dir = '/kaggle/input/o-haze/O-HAZY/GT'\n",
    "\n",
    "# hazeeffected_images_dir_train = '/kaggle/input/nh-dense-haze/NH-HAZE-T/NH-HAZE-T/IN'\n",
    "# hazefree_images_dir_train = '/kaggle/input/nh-dense-haze/NH-HAZE-T/NH-HAZE-T/GT'\n",
    "# hazeeffected_images_dir_valid = '/kaggle/input/nh-dense-haze/NH-HAZE-V/NH-HAZE-V/IN'\n",
    "# hazefree_images_dir_valid = '/kaggle/input/nh-dense-haze/NH-HAZE-V/NH-HAZE-V/GT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86a8529b",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.947087Z",
     "iopub.status.busy": "2025-04-12T13:09:35.946780Z",
     "iopub.status.idle": "2025-04-12T13:09:35.952544Z",
     "shell.execute_reply": "2025-04-12T13:09:35.951793Z"
    },
    "papermill": {
     "duration": 0.019086,
     "end_time": "2025-04-12T13:09:35.953847",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.934761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_log(epoch, num_epochs, one_epoch_time, train_psnr, val_psnr, val_ssim, category):\n",
    "    log_dir = \"./training_log\"\n",
    "    os.makedirs(log_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    log_path = os.path.join(log_dir, f\"{category}_log.txt\")\n",
    "\n",
    "    print('({0:.0f}s) Epoch [{1}/{2}], Train_PSNR:{3:.2f}, Val_PSNR:{4:.2f}, Val_SSIM:{5:.4f}'\n",
    "          .format(one_epoch_time, epoch, num_epochs, train_psnr, val_psnr, val_ssim))\n",
    "\n",
    "    # --- Write the training log --- #\n",
    "    with open(log_path, 'a') as f:\n",
    "        print('Date: {0}, Time_Cost: {1:.0f}s, Epoch: [{2}/{3}], Train_PSNR: {4:.2f}, Val_PSNR: {5:.2f}, Val_SSIM: {6:.4f}'\n",
    "              .format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "                      one_epoch_time, epoch, num_epochs, train_psnr, val_psnr, val_ssim), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc867732",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:35.977373Z",
     "iopub.status.busy": "2025-04-12T13:09:35.977090Z",
     "iopub.status.idle": "2025-04-12T13:09:35.982283Z",
     "shell.execute_reply": "2025-04-12T13:09:35.981521Z"
    },
    "papermill": {
     "duration": 0.01846,
     "end_time": "2025-04-12T13:09:35.983598",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.965138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, category, lr_decay=0.90):\n",
    "    \"\"\"\n",
    "    Adjusts the learning rate based on the epoch and dataset category.\n",
    "\n",
    "    :param optimizer: The optimizer (e.g., Adam, SGD).\n",
    "    :param epoch: Current epoch number.\n",
    "    :param category: Dataset category ('indoor', 'outdoor', or 'NH').\n",
    "    :param lr_decay: Multiplicative factor for learning rate decay.\n",
    "    \"\"\"\n",
    "    # Define learning rate decay steps based on category\n",
    "    step_dict = {'indoor': 18, 'outdoor': 3, 'NH': 20}\n",
    "    step = step_dict.get(category, 3)  # Default step size if category is unknown\n",
    "\n",
    "    # Decay learning rate at the specified step\n",
    "    if epoch > 0 and epoch % step == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= lr_decay\n",
    "            print(f\"Epoch {epoch}: Learning rate adjusted to {param_group['lr']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8022f81",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 0.011722,
     "end_time": "2025-04-12T13:09:36.006955",
     "exception": false,
     "start_time": "2025-04-12T13:09:35.995233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Perceptual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1225b9",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:36.030578Z",
     "iopub.status.busy": "2025-04-12T13:09:36.030296Z",
     "iopub.status.idle": "2025-04-12T13:09:36.037112Z",
     "shell.execute_reply": "2025-04-12T13:09:36.036372Z"
    },
    "papermill": {
     "duration": 0.020068,
     "end_time": "2025-04-12T13:09:36.038381",
     "exception": false,
     "start_time": "2025-04-12T13:09:36.018313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Perceptual Feature Loss Network --- #\n",
    "class PerceptualLossNet(nn.Module):\n",
    "    def __init__(self, vgg_model):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = vgg_model\n",
    "        self.feature_layers = {'3': \"low_level\", '8': \"mid_level\", '15': \"high_level\"}\n",
    "\n",
    "    def get_feature_maps(self, x):\n",
    "        feature_maps = []\n",
    "        for layer_id, layer in self.feature_extractor.named_children():\n",
    "            x = layer(x)\n",
    "            if layer_id in self.feature_layers:\n",
    "                feature_maps.append(x)\n",
    "        return feature_maps\n",
    "\n",
    "    def forward(self, predicted, target):\n",
    "        pred_features = self.get_feature_maps(predicted)\n",
    "        target_features = self.get_feature_maps(target)\n",
    "        \n",
    "        # Compute perceptual loss as mean squared error across feature maps\n",
    "        loss = torch.stack([F.mse_loss(p, t) for p, t in zip(pred_features, target_features)]).mean()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "class SSFM(nn.Module):\n",
    "    def __init__(self, loss_type='l1'):\n",
    "        super(SSFM, self).__init__()\n",
    "        assert loss_type in ['l1', 'l2'], \"loss_type must be 'l1' or 'l2'\"\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "    def forward(self, student_feats, teacher_feats):\n",
    "        \"\"\"\n",
    "        student_feats: List of feature maps from student RDBs [rdb1, rdb2, rdb3, rdb4]\n",
    "        teacher_feats: List of corresponding feature maps from teacher\n",
    "        \"\"\"\n",
    "        assert len(student_feats) == len(teacher_feats), \"Feature lists must match\"\n",
    "\n",
    "        total_loss = 0.0\n",
    "        for s_feat, t_feat in zip(student_feats, teacher_feats):\n",
    "            # Match resolution\n",
    "            if s_feat.shape != t_feat.shape:\n",
    "                t_feat = F.interpolate(t_feat, size=s_feat.shape[2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "            if self.loss_type == 'l1':\n",
    "                loss = F.l1_loss(s_feat, t_feat)\n",
    "            else:\n",
    "                loss = F.mse_loss(s_feat, t_feat)\n",
    "            \n",
    "            total_loss += loss\n",
    "\n",
    "        return total_loss / len(student_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb445d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:36.062427Z",
     "iopub.status.busy": "2025-04-12T13:09:36.062147Z",
     "iopub.status.idle": "2025-04-12T13:09:41.385390Z",
     "shell.execute_reply": "2025-04-12T13:09:41.384594Z"
    },
    "papermill": {
     "duration": 5.336581,
     "end_time": "2025-04-12T13:09:41.386705",
     "exception": false,
     "start_time": "2025-04-12T13:09:36.050124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0.00/528M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  3%|▎         | 13.5M/528M [00:00<00:03, 141MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  7%|▋         | 34.8M/528M [00:00<00:02, 189MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 11%|█         | 55.8M/528M [00:00<00:02, 203MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 14%|█▍        | 75.1M/528M [00:00<00:02, 199MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 18%|█▊        | 94.1M/528M [00:00<00:02, 198MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 21%|██▏       | 113M/528M [00:00<00:02, 198MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|██▌       | 132M/528M [00:00<00:02, 199MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 29%|██▊       | 151M/528M [00:00<00:01, 198MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 32%|███▏      | 170M/528M [00:00<00:01, 198MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 36%|███▌      | 190M/528M [00:01<00:01, 199MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|███▉      | 209M/528M [00:01<00:01, 200MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 43%|████▎     | 228M/528M [00:01<00:01, 199MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 47%|████▋     | 247M/528M [00:01<00:01, 199MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████     | 266M/528M [00:01<00:01, 199MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▍    | 285M/528M [00:01<00:01, 197MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 58%|█████▊    | 304M/528M [00:01<00:01, 197MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 61%|██████▏   | 323M/528M [00:01<00:01, 198MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|██████▍   | 343M/528M [00:01<00:00, 199MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 69%|██████▊   | 362M/528M [00:01<00:00, 192MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 72%|███████▏  | 380M/528M [00:02<00:00, 190MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 76%|███████▌  | 402M/528M [00:02<00:00, 200MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|███████▉  | 421M/528M [00:02<00:00, 200MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 83%|████████▎ | 440M/528M [00:02<00:00, 199MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 87%|████████▋ | 459M/528M [00:02<00:00, 198MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 91%|█████████ | 478M/528M [00:02<00:00, 198MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 94%|█████████▍| 497M/528M [00:02<00:00, 198MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 98%|█████████▊| 516M/528M [00:02<00:00, 198MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "100%|██████████| 528M/528M [00:02<00:00, 197MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model weights loaded from /kaggle/input/reside-dehaze/pytorch/default/2/formernewreside_haze_iter_85.pth\n",
      "📊 Total Trainable Parameters: 4,645,694\n"
     ]
    }
   ],
   "source": [
    "# --- Imports --- #\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "# --- Device Setup --- #\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_ids = list(range(torch.cuda.device_count()))\n",
    "\n",
    "# --- Initialize Model --- #\n",
    "net = DeepGuidedNetwork().to(device)\n",
    "\n",
    "# --- Enable Multi-GPU (if available) --- #\n",
    "if len(device_ids) > 1:\n",
    "    net = nn.DataParallel(net, device_ids=device_ids)\n",
    "\n",
    "# --- Optimizer --- #\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# --- Load Pretrained VGG16 for Perceptual Loss --- #\n",
    "vgg_features = vgg16(pretrained=True).features[:16].to(device)\n",
    "for param in vgg_features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "loss_network = PerceptualLossNet(vgg_features)\n",
    "loss_network.eval()\n",
    "\n",
    "# --- Load Model Weights (if available) --- #\n",
    "model_name = 'formernew'\n",
    "# checkpoint_path = f\"{model_name}_{category}_haze_best_{version}\"\n",
    "checkpoint_path = \"/kaggle/input/reside-dehaze/pytorch/default/2/formernewreside_haze_iter_85.pth\" \n",
    "\n",
    "try:\n",
    "    net.load_state_dict(torch.load(checkpoint_path, weights_only=False, map_location=torch.device('cpu')))\n",
    "    print(f\"✅ Model weights loaded from {checkpoint_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"⚠️ No pretrained weights found at {checkpoint_path}\")\n",
    "\n",
    "# --- Compute Total Trainable Parameters --- #\n",
    "total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f\"📊 Total Trainable Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a15b1c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:41.413893Z",
     "iopub.status.busy": "2025-04-12T13:09:41.413649Z",
     "iopub.status.idle": "2025-04-12T13:09:41.418873Z",
     "shell.execute_reply": "2025-04-12T13:09:41.418235Z"
    },
    "papermill": {
     "duration": 0.019715,
     "end_time": "2025-04-12T13:09:41.420112",
     "exception": false,
     "start_time": "2025-04-12T13:09:41.400397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeatureAffinityModule(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(FeatureAffinityModule, self).__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "    def forward(self, student_features, teacher_features):\n",
    "        # Normalize features\n",
    "        student_norm = F.normalize(student_features.view(student_features.size(0), self.channels, -1), dim=2)\n",
    "        teacher_norm = F.normalize(teacher_features.view(teacher_features.size(0), self.channels, -1), dim=2)\n",
    "\n",
    "        # Compute affinity matrices\n",
    "        student_affinity = torch.bmm(student_norm, student_norm.transpose(1, 2))\n",
    "        teacher_affinity = torch.bmm(teacher_norm, teacher_norm.transpose(1, 2))\n",
    "\n",
    "        # Compute KL divergence\n",
    "        loss = F.kl_div(F.log_softmax(student_affinity, dim=-1),\n",
    "                        F.softmax(teacher_affinity, dim=-1),\n",
    "                        reduction='batchmean')\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b2069e2",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:09:41.446417Z",
     "iopub.status.busy": "2025-04-12T13:09:41.446212Z",
     "iopub.status.idle": "2025-04-12T13:10:04.744659Z",
     "shell.execute_reply": "2025-04-12T13:10:04.743666Z"
    },
    "papermill": {
     "duration": 23.313227,
     "end_time": "2025-04-12T13:10:04.746196",
     "exception": false,
     "start_time": "2025-04-12T13:09:41.432969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4800, Validation samples: 1200\n"
     ]
    }
   ],
   "source": [
    "# Create train and validation datasets\n",
    "train_dataset = HazeDataset(crop_size=crop_size, \n",
    "                            hazeeffected_images_dir=hazeeffected_images_dir_train,\n",
    "                            hazefree_images_dir=hazefree_images_dir_train,\n",
    "                            split=\"train\")\n",
    "\n",
    "val_dataset = HazeDataset(crop_size=crop_size, \n",
    "                          hazeeffected_images_dir=hazeeffected_images_dir_train,\n",
    "                          hazefree_images_dir=hazefree_images_dir_train,\n",
    "                          split=\"valid\")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af7054ec",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:04.773195Z",
     "iopub.status.busy": "2025-04-12T13:10:04.772893Z",
     "iopub.status.idle": "2025-04-12T13:10:04.776689Z",
     "shell.execute_reply": "2025-04-12T13:10:04.776094Z"
    },
    "papermill": {
     "duration": 0.018274,
     "end_time": "2025-04-12T13:10:04.777834",
     "exception": false,
     "start_time": "2025-04-12T13:10:04.759560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f0f1ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:04.804155Z",
     "iopub.status.busy": "2025-04-12T13:10:04.803883Z",
     "iopub.status.idle": "2025-04-12T13:10:04.812124Z",
     "shell.execute_reply": "2025-04-12T13:10:04.811299Z"
    },
    "papermill": {
     "duration": 0.022717,
     "end_time": "2025-04-12T13:10:04.813435",
     "exception": false,
     "start_time": "2025-04-12T13:10:04.790718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, lr_dir, hr_dir, scale='x2', split='train', split_ratio=0.9):\n",
    "        \"\"\"\n",
    "        Super-Resolution dataset that matches LR and HR image pairs based on naming pattern,\n",
    "        with support for train/val split.\n",
    "\n",
    "        Args:\n",
    "            lr_dir (str): Directory containing low-resolution images (e.g., x2, x3, x4).\n",
    "            hr_dir (str): Directory containing high-resolution images.\n",
    "            scale (str): Scale suffix (e.g., 'x2', 'x3', 'x4').\n",
    "            split (str): Either 'train' or 'val'.\n",
    "            split_ratio (float): Ratio of training data (e.g., 0.9 means 90% train, 10% val).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_dir = hr_dir\n",
    "        self.scale = scale\n",
    "        self.split = split.lower()\n",
    "\n",
    "        valid_ext = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
    "        lr_images = sorted([\n",
    "            f for f in glob.glob(os.path.join(lr_dir, \"*.*\"))\n",
    "            if f.lower().endswith(valid_ext)\n",
    "        ])\n",
    "\n",
    "        lr_hr_pairs = []\n",
    "        for lr_path in lr_images:\n",
    "            lr_name = os.path.basename(lr_path)\n",
    "            hr_name = lr_name.replace(scale, '')\n",
    "            hr_path = os.path.join(hr_dir, hr_name)\n",
    "\n",
    "            if not os.path.exists(hr_path):\n",
    "                print(f\"Warning: Ground-truth missing for {lr_name}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            lr_hr_pairs.append((lr_path, hr_path))\n",
    "\n",
    "        if not lr_hr_pairs:\n",
    "            raise ValueError(\"No matching LR-HR image pairs found.\")\n",
    "\n",
    "        # Split dataset\n",
    "        split_idx = int(len(lr_hr_pairs) * split_ratio)\n",
    "        if self.split == 'train':\n",
    "            self.lr_hr_pairs = lr_hr_pairs[:split_idx]\n",
    "        elif self.split == 'val':\n",
    "            self.lr_hr_pairs = lr_hr_pairs[split_idx:]\n",
    "        else:\n",
    "            raise ValueError(\"split must be either 'train' or 'val'\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_hr_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_path, hr_path = self.lr_hr_pairs[idx]\n",
    "\n",
    "        try:\n",
    "            lr_img = Image.open(lr_path).convert('RGB')\n",
    "            hr_img = Image.open(hr_path).convert('RGB')\n",
    "        except UnidentifiedImageError:\n",
    "            raise ValueError(f\"Unidentified image at {lr_path} or {hr_path}\")\n",
    "\n",
    "        return ToTensor()(lr_img), ToTensor()(hr_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "069446cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:04.839655Z",
     "iopub.status.busy": "2025-04-12T13:10:04.839424Z",
     "iopub.status.idle": "2025-04-12T13:10:04.843726Z",
     "shell.execute_reply": "2025-04-12T13:10:04.842940Z"
    },
    "papermill": {
     "duration": 0.018734,
     "end_time": "2025-04-12T13:10:04.844884",
     "exception": false,
     "start_time": "2025-04-12T13:10:04.826150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    min_height = min([x[0].shape[1] for x in batch])//4\n",
    "    min_width = min([x[0].shape[2] for x in batch])//4\n",
    "    resized_batch = [(TF.resize(x[0], [min_height, min_width]), TF.resize(x[1], [min_height, min_width])) for x in batch]\n",
    "    return torch.utils.data.dataloader.default_collate(resized_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf67adc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:04.871036Z",
     "iopub.status.busy": "2025-04-12T13:10:04.870788Z",
     "iopub.status.idle": "2025-04-12T13:10:04.873753Z",
     "shell.execute_reply": "2025-04-12T13:10:04.872978Z"
    },
    "papermill": {
     "duration": 0.017538,
     "end_time": "2025-04-12T13:10:04.875079",
     "exception": false,
     "start_time": "2025-04-12T13:10:04.857541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Paths\n",
    "# sr_hr_dir = '/kaggle/input/flickr2k/Flickr2K/Flickr2K_HR'\n",
    "# sr_lr_dir = '/kaggle/input/flickr2k/Flickr2K/Flickr2K_LR_bicubic/X2'\n",
    "\n",
    "# # Train SR DataLoader\n",
    "# sr_train_dataset = SRDataset(lr_dir, hr_dir, scale='x2', split='train')\n",
    "# sr_valid_dataset = SRDataset(lr_dir, hr_dir, scale='x2', split='val')\n",
    "\n",
    "# sr_train_loader = DataLoader(sr_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=custom_collate_fn)\n",
    "\n",
    "# # If you have a separate validation split:\n",
    "# sr_val_loader = DataLoader(sr_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2, collate_fn=custom_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "193edb5d",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:04.901358Z",
     "iopub.status.busy": "2025-04-12T13:10:04.901159Z",
     "iopub.status.idle": "2025-04-12T13:10:04.903618Z",
     "shell.execute_reply": "2025-04-12T13:10:04.903008Z"
    },
    "papermill": {
     "duration": 0.016903,
     "end_time": "2025-04-12T13:10:04.904752",
     "exception": false,
     "start_time": "2025-04-12T13:10:04.887849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data_loader = DataLoader(TrainData(crop_size, hazeeffected_images_dir_train, hazefree_images_dir_train), batch_size=train_batch_size, shuffle=True)\n",
    "# val_data_loader = DataLoader(TrainData(crop_size, hazeeffected_images_dir_valid, hazefree_images_dir_valid), batch_size=val_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65e8fea3",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:04.930908Z",
     "iopub.status.busy": "2025-04-12T13:10:04.930697Z",
     "iopub.status.idle": "2025-04-12T13:10:04.933333Z",
     "shell.execute_reply": "2025-04-12T13:10:04.932729Z"
    },
    "papermill": {
     "duration": 0.016832,
     "end_time": "2025-04-12T13:10:04.934413",
     "exception": false,
     "start_time": "2025-04-12T13:10:04.917581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_size = len(TrainData(crop_size, hazeeffected_images_dir_train, hazefree_images_dir_train))\n",
    "# val_size = len(TrainData(crop_size, hazeeffected_images_dir_valid, hazefree_images_dir_valid))\n",
    "\n",
    "# print(f\"Train Size: {train_size}, Val Size: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30b9090f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:04.960594Z",
     "iopub.status.busy": "2025-04-12T13:10:04.960388Z",
     "iopub.status.idle": "2025-04-12T13:10:11.787320Z",
     "shell.execute_reply": "2025-04-12T13:10:11.785245Z"
    },
    "papermill": {
     "duration": 6.842293,
     "end_time": "2025-04-12T13:10:11.789404",
     "exception": false,
     "start_time": "2025-04-12T13:10:04.947111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- SR Dataset Setup --- #\n",
    "sr_enabled = True\n",
    "if sr_enabled:\n",
    "    sr_hr_dir = '/kaggle/input/flickr2k/Flickr2K/Flickr2K_HR'\n",
    "    sr_lr_dir = '/kaggle/input/flickr2k/Flickr2K/Flickr2K_LR_bicubic/X2'\n",
    "    sr_train_dataset = SRDataset(lr_dir=sr_lr_dir, hr_dir=sr_hr_dir, scale='x2', split='train')\n",
    "    sr_val_dataset = SRDataset(lr_dir=sr_lr_dir, hr_dir=sr_hr_dir, scale='x2', split='val')\n",
    "    sr_train_loader = DataLoader(sr_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=custom_collate_fn)\n",
    "    sr_val_loader = DataLoader(sr_val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=custom_collate_fn)\n",
    "    sr_iter = iter(sr_train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "825c61a5",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:11.842444Z",
     "iopub.status.busy": "2025-04-12T13:10:11.842014Z",
     "iopub.status.idle": "2025-04-12T13:10:12.077664Z",
     "shell.execute_reply": "2025-04-12T13:10:12.076973Z"
    },
    "papermill": {
     "duration": 0.272846,
     "end_time": "2025-04-12T13:10:12.082208",
     "exception": false,
     "start_time": "2025-04-12T13:10:11.809362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 128, 128]) torch.Size([6, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for i,o in train_data_loader:\n",
    "    print(i.shape, o.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f363d8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:12.194883Z",
     "iopub.status.busy": "2025-04-12T13:10:12.194342Z",
     "iopub.status.idle": "2025-04-12T13:10:14.578583Z",
     "shell.execute_reply": "2025-04-12T13:10:14.577477Z"
    },
    "papermill": {
     "duration": 2.453133,
     "end_time": "2025-04-12T13:10:14.580358",
     "exception": false,
     "start_time": "2025-04-12T13:10:12.127225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 175, 255]) torch.Size([2, 3, 175, 255])\n"
     ]
    }
   ],
   "source": [
    "for i,o in sr_val_loader:\n",
    "    print(i.shape, o.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d942c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:14.608304Z",
     "iopub.status.busy": "2025-04-12T13:10:14.608029Z",
     "iopub.status.idle": "2025-04-12T13:10:14.611574Z",
     "shell.execute_reply": "2025-04-12T13:10:14.611005Z"
    },
    "papermill": {
     "duration": 0.018508,
     "end_time": "2025-04-12T13:10:14.612764",
     "exception": false,
     "start_time": "2025-04-12T13:10:14.594256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b93059f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T13:10:14.642391Z",
     "iopub.status.busy": "2025-04-12T13:10:14.642057Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-04-12T13:10:14.625824",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dehazing Init Val] PSNR: 28.81, SSIM: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Init Val] PSNR: 27.26, SSIM: 0.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 29.76, SSIM: 0.9338\n",
      "(479s) Epoch [1/85], Train_PSNR:12.36, Val_PSNR:12.61, Val_SSIM:0.4007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 25.77, SSIM: 0.8795\n",
      "(412s) Epoch [2/85], Train_PSNR:12.21, Val_PSNR:12.80, Val_SSIM:0.4087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 17.86, SSIM: 0.7113\n",
      "(416s) Epoch [3/85], Train_PSNR:12.19, Val_PSNR:12.00, Val_SSIM:0.3621\n",
      "Epoch 3: Learning rate adjusted to 0.000090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 36.18, SSIM: 0.9714\n",
      "(422s) Epoch [4/85], Train_PSNR:12.18, Val_PSNR:12.67, Val_SSIM:0.3995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 17.57, SSIM: 0.7292\n",
      "(436s) Epoch [5/85], Train_PSNR:12.35, Val_PSNR:11.60, Val_SSIM:0.3725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 35.60, SSIM: 0.9582\n",
      "(445s) Epoch [6/85], Train_PSNR:12.16, Val_PSNR:12.57, Val_SSIM:0.4083\n",
      "Epoch 6: Learning rate adjusted to 0.000081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 37.72, SSIM: 0.9740\n",
      "(452s) Epoch [7/85], Train_PSNR:12.22, Val_PSNR:12.91, Val_SSIM:0.4182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 33.14, SSIM: 0.9387\n",
      "(463s) Epoch [8/85], Train_PSNR:12.44, Val_PSNR:12.86, Val_SSIM:0.4072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 37.89, SSIM: 0.9790\n",
      "(468s) Epoch [9/85], Train_PSNR:12.36, Val_PSNR:12.32, Val_SSIM:0.3975\n",
      "Epoch 9: Learning rate adjusted to 0.000073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 37.85, SSIM: 0.9748\n",
      "(479s) Epoch [10/85], Train_PSNR:12.37, Val_PSNR:12.91, Val_SSIM:0.3997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 40.20, SSIM: 0.9834\n",
      "(490s) Epoch [11/85], Train_PSNR:12.50, Val_PSNR:12.75, Val_SSIM:0.3874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 40.86, SSIM: 0.9881\n",
      "(499s) Epoch [12/85], Train_PSNR:12.63, Val_PSNR:12.99, Val_SSIM:0.4127\n",
      "Epoch 12: Learning rate adjusted to 0.000066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 39.92, SSIM: 0.9815\n",
      "(504s) Epoch [13/85], Train_PSNR:12.64, Val_PSNR:12.89, Val_SSIM:0.4123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 38.93, SSIM: 0.9711\n",
      "(514s) Epoch [14/85], Train_PSNR:12.46, Val_PSNR:12.69, Val_SSIM:0.3876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 38.61, SSIM: 0.9693\n",
      "(517s) Epoch [15/85], Train_PSNR:12.45, Val_PSNR:12.69, Val_SSIM:0.3967\n",
      "Epoch 15: Learning rate adjusted to 0.000059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 15.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 38.45, SSIM: 0.9692\n",
      "(522s) Epoch [16/85], Train_PSNR:12.64, Val_PSNR:12.67, Val_SSIM:0.4031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 42.76, SSIM: 0.9923\n",
      "(536s) Epoch [17/85], Train_PSNR:12.55, Val_PSNR:13.15, Val_SSIM:0.4250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 41.09, SSIM: 0.9899\n",
      "(548s) Epoch [18/85], Train_PSNR:12.76, Val_PSNR:13.35, Val_SSIM:0.4067\n",
      "Epoch 18: Learning rate adjusted to 0.000053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 42.80, SSIM: 0.9918\n",
      "(556s) Epoch [19/85], Train_PSNR:12.55, Val_PSNR:13.01, Val_SSIM:0.4014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 40.03, SSIM: 0.9790\n",
      "(565s) Epoch [20/85], Train_PSNR:12.67, Val_PSNR:12.65, Val_SSIM:0.3900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 20.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 40.80, SSIM: 0.9748\n",
      "(570s) Epoch [21/85], Train_PSNR:12.53, Val_PSNR:12.84, Val_SSIM:0.4056\n",
      "Epoch 21: Learning rate adjusted to 0.000048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 43.27, SSIM: 0.9900\n",
      "(573s) Epoch [22/85], Train_PSNR:12.73, Val_PSNR:12.95, Val_SSIM:0.4014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 44.00, SSIM: 0.9942\n",
      "(585s) Epoch [23/85], Train_PSNR:12.79, Val_PSNR:13.15, Val_SSIM:0.4158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 42.82, SSIM: 0.9886\n",
      "(601s) Epoch [24/85], Train_PSNR:12.90, Val_PSNR:13.06, Val_SSIM:0.4019\n",
      "Epoch 24: Learning rate adjusted to 0.000043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 42.28, SSIM: 0.9919\n",
      "(601s) Epoch [25/85], Train_PSNR:12.89, Val_PSNR:13.23, Val_SSIM:0.4154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 25.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 43.25, SSIM: 0.9926\n",
      "(612s) Epoch [26/85], Train_PSNR:12.90, Val_PSNR:13.09, Val_SSIM:0.4114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 43.75, SSIM: 0.9897\n",
      "(624s) Epoch [27/85], Train_PSNR:12.93, Val_PSNR:13.06, Val_SSIM:0.4070\n",
      "Epoch 27: Learning rate adjusted to 0.000039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 44.57, SSIM: 0.9945\n",
      "(626s) Epoch [28/85], Train_PSNR:13.01, Val_PSNR:13.01, Val_SSIM:0.4029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 44.81, SSIM: 0.9948\n",
      "(640s) Epoch [29/85], Train_PSNR:13.07, Val_PSNR:13.54, Val_SSIM:0.4169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 41.44, SSIM: 0.9752\n",
      "(655s) Epoch [30/85], Train_PSNR:13.10, Val_PSNR:13.52, Val_SSIM:0.4086\n",
      "Epoch 30: Learning rate adjusted to 0.000035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 44.67, SSIM: 0.9920\n",
      "(662s) Epoch [31/85], Train_PSNR:13.18, Val_PSNR:13.39, Val_SSIM:0.4172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 45.21, SSIM: 0.9960\n",
      "(669s) Epoch [32/85], Train_PSNR:13.06, Val_PSNR:13.29, Val_SSIM:0.4067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 45.47, SSIM: 0.9958\n",
      "(673s) Epoch [33/85], Train_PSNR:13.17, Val_PSNR:13.33, Val_SSIM:0.4073\n",
      "Epoch 33: Learning rate adjusted to 0.000031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 42.45, SSIM: 0.9784\n",
      "(678s) Epoch [34/85], Train_PSNR:12.96, Val_PSNR:13.37, Val_SSIM:0.4071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 45.27, SSIM: 0.9946\n",
      "(700s) Epoch [35/85], Train_PSNR:13.15, Val_PSNR:13.20, Val_SSIM:0.4099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 45.48, SSIM: 0.9947\n",
      "(709s) Epoch [36/85], Train_PSNR:13.22, Val_PSNR:13.65, Val_SSIM:0.4192\n",
      "Epoch 36: Learning rate adjusted to 0.000028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 45.06, SSIM: 0.9922\n",
      "(716s) Epoch [37/85], Train_PSNR:13.23, Val_PSNR:13.81, Val_SSIM:0.4160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 45.70, SSIM: 0.9946\n",
      "(731s) Epoch [38/85], Train_PSNR:13.31, Val_PSNR:13.58, Val_SSIM:0.4140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 45.48, SSIM: 0.9959\n",
      "(738s) Epoch [39/85], Train_PSNR:13.21, Val_PSNR:13.70, Val_SSIM:0.4320\n",
      "Epoch 39: Learning rate adjusted to 0.000025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 45.78, SSIM: 0.9963\n",
      "(743s) Epoch [40/85], Train_PSNR:13.19, Val_PSNR:13.46, Val_SSIM:0.4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.22, SSIM: 0.9961\n",
      "(753s) Epoch [41/85], Train_PSNR:13.34, Val_PSNR:13.59, Val_SSIM:0.4115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.22, SSIM: 0.9959\n",
      "(762s) Epoch [42/85], Train_PSNR:13.38, Val_PSNR:13.52, Val_SSIM:0.4141\n",
      "Epoch 42: Learning rate adjusted to 0.000023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.20, SSIM: 0.9967\n",
      "(772s) Epoch [43/85], Train_PSNR:13.34, Val_PSNR:13.51, Val_SSIM:0.4043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.22, SSIM: 0.9963\n",
      "(780s) Epoch [44/85], Train_PSNR:13.30, Val_PSNR:13.67, Val_SSIM:0.4280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.37, SSIM: 0.9964\n",
      "(788s) Epoch [45/85], Train_PSNR:13.39, Val_PSNR:13.78, Val_SSIM:0.4080\n",
      "Epoch 45: Learning rate adjusted to 0.000021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 45.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.61, SSIM: 0.9968\n",
      "(791s) Epoch [46/85], Train_PSNR:13.43, Val_PSNR:13.56, Val_SSIM:0.4146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.61, SSIM: 0.9967\n",
      "(804s) Epoch [47/85], Train_PSNR:13.40, Val_PSNR:13.71, Val_SSIM:0.4208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.68, SSIM: 0.9969\n",
      "(817s) Epoch [48/85], Train_PSNR:13.40, Val_PSNR:13.70, Val_SSIM:0.4227\n",
      "Epoch 48: Learning rate adjusted to 0.000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.71, SSIM: 0.9969\n",
      "(823s) Epoch [49/85], Train_PSNR:13.47, Val_PSNR:13.78, Val_SSIM:0.4250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.59, SSIM: 0.9969\n",
      "(838s) Epoch [50/85], Train_PSNR:13.50, Val_PSNR:13.68, Val_SSIM:0.4011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 50.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.00, SSIM: 0.9970\n",
      "(851s) Epoch [51/85], Train_PSNR:13.55, Val_PSNR:13.67, Val_SSIM:0.4316\n",
      "Epoch 51: Learning rate adjusted to 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.05, SSIM: 0.9973\n",
      "(858s) Epoch [52/85], Train_PSNR:13.54, Val_PSNR:13.99, Val_SSIM:0.4241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.02, SSIM: 0.9973\n",
      "(869s) Epoch [53/85], Train_PSNR:13.49, Val_PSNR:13.70, Val_SSIM:0.4141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.13, SSIM: 0.9965\n",
      "(869s) Epoch [54/85], Train_PSNR:13.62, Val_PSNR:13.84, Val_SSIM:0.4146\n",
      "Epoch 54: Learning rate adjusted to 0.000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.22, SSIM: 0.9973\n",
      "(865s) Epoch [55/85], Train_PSNR:13.63, Val_PSNR:13.84, Val_SSIM:0.4301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 55.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.23, SSIM: 0.9973\n",
      "(882s) Epoch [56/85], Train_PSNR:13.56, Val_PSNR:13.87, Val_SSIM:0.4123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.34, SSIM: 0.9971\n",
      "(895s) Epoch [57/85], Train_PSNR:13.57, Val_PSNR:13.74, Val_SSIM:0.4123\n",
      "Epoch 57: Learning rate adjusted to 0.000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.42, SSIM: 0.9971\n",
      "(901s) Epoch [58/85], Train_PSNR:13.55, Val_PSNR:13.98, Val_SSIM:0.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.52, SSIM: 0.9973\n",
      "(925s) Epoch [59/85], Train_PSNR:13.62, Val_PSNR:13.76, Val_SSIM:0.4189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.50, SSIM: 0.9975\n",
      "(918s) Epoch [60/85], Train_PSNR:13.64, Val_PSNR:13.93, Val_SSIM:0.4199\n",
      "Epoch 60: Learning rate adjusted to 0.000012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in epoch 60.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 46.96, SSIM: 0.9973\n",
      "(929s) Epoch [61/85], Train_PSNR:13.74, Val_PSNR:13.50, Val_SSIM:0.4102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.54, SSIM: 0.9973\n",
      "(935s) Epoch [62/85], Train_PSNR:13.61, Val_PSNR:13.85, Val_SSIM:0.4248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/85], Iteration [765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SR Val] PSNR: 47.59, SSIM: 0.9976\n",
      "(936s) Epoch [63/85], Train_PSNR:13.69, Val_PSNR:14.02, Val_SSIM:0.4196\n",
      "Epoch 63: Learning rate adjusted to 0.000011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/85], Iteration [765]\n"
     ]
    }
   ],
   "source": [
    "# --- Teacher Network --- #\n",
    "teacher_net = DeepGuidedNetwork(radius=1).to(device)\n",
    "# teacher_net.load_state_dict(torch.load('teacher_model.pth'))\n",
    "# teacher_net.eval()\n",
    "\n",
    "# --- Feature Affinity Module --- #\n",
    "fam = FeatureAffinityModule(channels=64).to(device)\n",
    "ssfm_loss = SSFM(loss_type='l1') \n",
    "\n",
    "\n",
    "# --- Initial Validation --- #\n",
    "old_val_psnr, old_val_ssim = validationB(net, val_data_loader, device, category)\n",
    "print(f\"[Dehazing Init Val] PSNR: {old_val_psnr:.2f}, SSIM: {old_val_ssim:.4f}\")\n",
    "if sr_enabled:\n",
    "    sr_val_psnr, sr_val_ssim = validation_sr(net, sr_val_loader, device)\n",
    "    print(f\"[SR Init Val] PSNR: {sr_val_psnr:.2f}, SSIM: {sr_val_ssim:.4f}\")\n",
    "\n",
    "# --- Training Loop --- #\n",
    "best_psnr = old_val_psnr\n",
    "train_psnr_prev = 0\n",
    "distillation_weight = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    psnr_list = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    adjust_learning_rate(optimizer, epoch, category=category)\n",
    "    net.train()\n",
    "\n",
    "    for batch_id, (haze, gt) in enumerate(train_data_loader):\n",
    "        haze, gt = haze.to(device), gt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass - Student\n",
    "        dehaze, base, s1, s2, s3, s4 = net(haze)\n",
    "\n",
    "        # Teacher Output\n",
    "        with torch.no_grad():\n",
    "            teacher_dehaze, _, t1, t2, t3, t4 = teacher_net(haze)\n",
    "\n",
    "        # Losses\n",
    "        base_loss = F.smooth_l1_loss(base, gt)\n",
    "        smooth_loss = F.smooth_l1_loss(dehaze, gt)\n",
    "        perceptual_loss = loss_network(dehaze, gt)\n",
    "        \n",
    "        student_feats = [s1, s2, s3, s4]  \n",
    "        teacher_feats = [t1, t2, t3, t4]  \n",
    "        s_loss = ssfm_loss(student_feats, teacher_feats)\n",
    "        \n",
    "        distillation_loss = fam(dehaze, teacher_dehaze)\n",
    "        # print(\"distillation_loss: \", distillation_loss)\n",
    "        total_loss = smooth_loss + lambda_loss * perceptual_loss + base_loss + distillation_weight * distillation_loss + s_loss\n",
    "\n",
    "        # --- SR Training --- #\n",
    "        if sr_enabled:\n",
    "            try:\n",
    "                sr_lr, sr_hr = next(sr_iter)\n",
    "            except StopIteration:\n",
    "                sr_iter = iter(sr_train_loader)\n",
    "                sr_lr, sr_hr = next(sr_iter)\n",
    "            sr_lr, sr_hr = sr_lr.to(device), sr_hr.to(device)\n",
    "            sr_out, _ = net(sr_lr)\n",
    "            sr_loss = F.l1_loss(sr_out, sr_hr)\n",
    "            total_loss += sr_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        psnr_list.extend(to_psnr(dehaze, gt))\n",
    "\n",
    "        if batch_id % num_epochs == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Iteration [{batch_id}]\")\n",
    "\n",
    "    # Save model checkpoint\n",
    "    if epoch % 5 == 0:\n",
    "        iter_model_path = f\"{model_name}{category}_haze_iter_{epoch}.pth\"\n",
    "        torch.save(net.state_dict(), iter_model_path)\n",
    "        print(f\"Model saved in epoch {epoch}.\")\n",
    "\n",
    "    train_psnr = sum(psnr_list) / len(psnr_list)\n",
    "    model_path = f\"{model_name}{category}_haze_{version}.pth\"\n",
    "\n",
    "    # --- Validation --- #\n",
    "    net.eval()\n",
    "    val_psnr, val_ssim = validationB(net, val_data_loader, device, category)\n",
    "    if sr_enabled:\n",
    "        sr_val_psnr, sr_val_ssim = validation_sr(net, sr_val_loader, device)\n",
    "        print(f\"[SR Val] PSNR: {sr_val_psnr:.2f}, SSIM: {sr_val_ssim:.4f}\")\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    print_log(epoch + 1, num_epochs, epoch_duration, train_psnr, val_psnr, val_ssim, model_path)\n",
    "\n",
    "    if train_psnr < train_psnr_prev:\n",
    "        adjust_learning_rate(optimizer, num_epochs, category=category)\n",
    "\n",
    "    if val_psnr >= best_psnr:\n",
    "        best_model_path = f\"{model_name}{category}_haze_best_{version}.pth\"\n",
    "        torch.save(net.state_dict(), best_model_path)\n",
    "        best_psnr = val_psnr\n",
    "\n",
    "    train_psnr_prev = train_psnr\n",
    "\n",
    "# Final save\n",
    "final_path = f\"{model_name}{category}_final_{epoch}.pth\"\n",
    "torch.save(net.state_dict(), final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc02fe3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-12T12:00:19.116285Z",
     "iopub.status.idle": "2025-04-12T12:00:19.116583Z",
     "shell.execute_reply": "2025-04-12T12:00:19.116454Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "# model_path = \"/kaggle/input/rdb-and-transformer/pytorch/default/1/formernewnh_final_49.pth\"\n",
    "model_path = \"/kaggle/input/reside-dehaze/pytorch/default/3/formernewreside_haze_best_0.pth\"\n",
    "# model = DehazingNet().to(device)\n",
    "# model = SR_model(upscale_factor=1).to(device)\n",
    "# net.load_state_dict(torch.load(model_path, map_location=device))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944112a7",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2025-04-12T12:00:19.117251Z",
     "iopub.status.idle": "2025-04-12T12:00:19.117545Z",
     "shell.execute_reply": "2025-04-12T12:00:19.117419Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# LOAD TEST DATA\n",
    "# -----------------------------\n",
    "test_hazy_dir = \"/kaggle/input/reside6k/RESIDE-6K/test/hazy\"\n",
    "test_gt_dir = \"/kaggle/input/reside6k/RESIDE-6K/test/GT\"\n",
    "# test_hazy_dir = \"/kaggle/input/nh-dense-haze/NH-HAZE-T/NH-HAZE-T/IN\"\n",
    "# test_gt_dir = \"/kaggle/input/nh-dense-haze/NH-HAZE-T/NH-HAZE-T/GT\"\n",
    "\n",
    "hazy_images = sorted(glob.glob(os.path.join(test_hazy_dir, \"*.*\")))\n",
    "gt_images = sorted(glob.glob(os.path.join(test_gt_dir, \"*.*\")))\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "to_pil = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91a32a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-12T12:00:19.118248Z",
     "iopub.status.idle": "2025-04-12T12:00:19.118609Z",
     "shell.execute_reply": "2025-04-12T12:00:19.118480Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# INFERENCE & VISUALIZATION FOR SPECIFIC IMAGES\n",
    "# -----------------------------\n",
    "image_indices = [11, 12, 13,14]  # Indices of images to visualize\n",
    "\n",
    "plt.figure(figsize=(10, len(image_indices) * 5))\n",
    "\n",
    "for idx, i in enumerate(image_indices):\n",
    "    hazy_img = Image.open(hazy_images[i+1])\n",
    "    gt_img = Image.open(gt_images[i+1])\n",
    "\n",
    "    # Transform for model input\n",
    "    input_tensor = transform(hazy_img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        res = net(input_tensor)\n",
    "        print(res[0].shape)\n",
    "        output_tensor = res[0].cpu().squeeze(0)\n",
    "\n",
    "    # Convert back to image\n",
    "    output_img = to_pil(output_tensor)\n",
    "\n",
    "    # Display results\n",
    "    plt.subplot(len(image_indices), 3, 3 * idx + 1)\n",
    "    plt.imshow(hazy_img)\n",
    "    plt.title(f\"Hazy Input \")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(len(image_indices), 3, 3 * idx + 2)\n",
    "    plt.imshow(output_img)\n",
    "    plt.title(f\"Dehazed Output \")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(len(image_indices), 3, 3 * idx + 3)\n",
    "    plt.imshow(gt_img)\n",
    "    plt.title(f\"Ground Truth \")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac37df8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-12T12:00:19.119473Z",
     "iopub.status.idle": "2025-04-12T12:00:19.119866Z",
     "shell.execute_reply": "2025-04-12T12:00:19.119676Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# INFERENCE & VISUALIZATION FOR SPECIFIC IMAGES\n",
    "# -----------------------------\n",
    "image_indices = [70, 75, 90, 100]  # Indices of images to visualize\n",
    "\n",
    "plt.figure(figsize=(10, len(image_indices) * 5))\n",
    "\n",
    "for idx, i in enumerate(image_indices):\n",
    "    hazy_img = Image.open(hazy_images[i+1])\n",
    "    gt_img = Image.open(gt_images[i+1])\n",
    "\n",
    "    # Transform for model input\n",
    "    input_tensor = transform(hazy_img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        res = net(input_tensor)\n",
    "        print(res[0].shape)\n",
    "        output_tensor = res[0].cpu().squeeze(0)\n",
    "\n",
    "    # Convert back to image\n",
    "    output_img = to_pil(output_tensor)\n",
    "\n",
    "    # Display results\n",
    "    plt.subplot(len(image_indices), 3, 3 * idx + 1)\n",
    "    plt.imshow(hazy_img)\n",
    "    plt.title(f\"Hazy Input {i}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(len(image_indices), 3, 3 * idx + 2)\n",
    "    plt.imshow(output_img)\n",
    "    plt.title(f\"Dehazed Output {i}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(len(image_indices), 3, 3 * idx + 3)\n",
    "    plt.imshow(gt_img)\n",
    "    plt.title(f\"Ground Truth {i}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204829ba",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-12T12:00:19.120630Z",
     "iopub.status.idle": "2025-04-12T12:00:19.121026Z",
     "shell.execute_reply": "2025-04-12T12:00:19.120841Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# INFERENCE & VISUALIZATION FOR SPECIFIC IMAGES\n",
    "# -----------------------------\n",
    "image_indices = [1, 3, 5]  # Indices of images to visualize\n",
    "\n",
    "plt.figure(figsize=(10, len(image_indices) * 5))\n",
    "\n",
    "for idx, i in enumerate(image_indices):\n",
    "    hazy_img = Image.open(hazy_images[i+1])\n",
    "    gt_img = Image.open(gt_images[i+1])\n",
    "\n",
    "    # Transform for model input\n",
    "    input_tensor = transform(hazy_img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        res = net(input_tensor)\n",
    "        print(res[0].shape)\n",
    "        output_tensor = res[0].cpu().squeeze(0)\n",
    "\n",
    "    # Convert back to image\n",
    "    output_img = to_pil(output_tensor)\n",
    "\n",
    "    # Display results\n",
    "    plt.subplot(len(image_indices), 3, 3 * idx + 1)\n",
    "    plt.imshow(hazy_img)\n",
    "    plt.title(f\"Hazy Input {i}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(len(image_indices), 3, 3 * idx + 2)\n",
    "    plt.imshow(output_img)\n",
    "    plt.title(f\"Dehazed Output {i}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(len(image_indices), 3, 3 * idx + 3)\n",
    "    plt.imshow(gt_img)\n",
    "    plt.title(f\"Ground Truth {i}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 937211,
     "sourceId": 1587463,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6456606,
     "sourceId": 10417877,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6464114,
     "sourceId": 10443410,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2813430,
     "sourceId": 4853613,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 222875724,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 268224,
     "modelInstanceId": 246650,
     "sourceId": 287852,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 269124,
     "modelInstanceId": 247592,
     "sourceId": 288973,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 269124,
     "modelInstanceId": 247592,
     "sourceId": 297672,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 269124,
     "modelInstanceId": 247592,
     "sourceId": 299643,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-12T13:09:18.306161",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
